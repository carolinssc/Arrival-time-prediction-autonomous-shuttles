{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../../src')\n",
    "import os\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from data.datamodule import SHOWDataModule\n",
    "from models.gcn_model import NodeEncodedGCN, NodeEncodedGCN_tt, NodeEncodedGCN_1l, NodeEncodedGCN_2l, NodeEncodedGCN_3l\n",
    "\n",
    "\n",
    "def simple_model_evaluation(y_test, y_pred_test):\n",
    "    # Simple model evaluation that computes and prints MSE, RMSE and MAPE for the training and testing set\n",
    "\n",
    "    # train_error_mse = np.square(y_train - y_pred_train).sum() / y_train.shape[0]\n",
    "    test_error_mse = np.square(y_test - y_pred_test).sum() / y_test.shape[0]\n",
    "\n",
    "    # train_error_mape = (100 / y_train.shape[0]) * (\n",
    "    #    np.absolute(y_train - y_pred_train) / y_train\n",
    "    # ).sum()  # y_train should never be 0 since the travel time in a segment cannot be 0\n",
    "    test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
    "\n",
    "    test_error_mae = (1 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test)).sum()\n",
    "    print(\"-----------MSE----------\")\n",
    "    # print(\"Training error: {}\".format(train_error_mse))\n",
    "    print(\"Testing error: {}\".format(test_error_mse))\n",
    "    print(\"-----------RMSE----------\")\n",
    "    # print(\"Training error: {}\".format(np.sqrt(train_error_mse)))\n",
    "    print(\"Testing error: {}\".format(np.sqrt(test_error_mse)))\n",
    "    print(\"-----------MAPE----------\")\n",
    "    # print(\"Training error: {:.2f} %\".format(train_error_mape))\n",
    "    print(\"Testing error: {:.2f} %\".format(test_error_mape))\n",
    "    print(\"-----------MAE----------\")\n",
    "    print(\"Testing error: {}\".format(test_error_mae))\n",
    "    return test_error_mse, np.sqrt(test_error_mse), test_error_mape, test_error_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the checkpoint directory\n",
    "checkpoint_dir = '.'\n",
    "model_names = os.listdir(checkpoint_dir)\n",
    "\n",
    "# remove all files not ending on ckpt\n",
    "model_names = [model_name for model_name in model_names if model_name.endswith('ckpt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ne_gcn-3302-07271242.ckpt',\n",
       " 'ne_gcn-4762-07271242.ckpt',\n",
       " 'ne_gcn-5995-07271242.ckpt',\n",
       " 'ne_gcn-9389-07271242.ckpt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the datamodule\n",
    "site_name = 'TAMPERE_FINAL'\n",
    "transform = 'maxmin'\n",
    "batch_size = 64\n",
    "empty_graph = False\n",
    "time_kind = 'travel_times'\n",
    "data_module = SHOWDataModule(\n",
    "    site_name=site_name,\n",
    "    transform=transform,\n",
    "    num_lags=2,\n",
    "    train_frac=0.9,\n",
    "    batch_size=batch_size,\n",
    "    empty_graph=empty_graph,\n",
    "    verbose=False,\n",
    "    time_kind=time_kind,\n",
    ")\n",
    "transform = data_module.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-3302-07271242.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 16.97it/s]-----------MSE----------\n",
      "Testing error: 170.08367919921875\n",
      "-----------RMSE----------\n",
      "Testing error: 13.041613578796387\n",
      "-----------MAPE----------\n",
      "Testing error: 11.70 %\n",
      "-----------MAE----------\n",
      "Testing error: 9.44366455078125\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 16.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ne_gcn-4762-07271242.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 163.69it/s]-----------MSE----------\n",
      "Testing error: 167.94692993164062\n",
      "-----------RMSE----------\n",
      "Testing error: 12.959433555603027\n",
      "-----------MAPE----------\n",
      "Testing error: 11.35 %\n",
      "-----------MAE----------\n",
      "Testing error: 9.166473388671875\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 150.85it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-5995-07271242.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 164.75it/s]-----------MSE----------\n",
      "Testing error: 170.8033905029297\n",
      "-----------RMSE----------\n",
      "Testing error: 13.06917667388916\n",
      "-----------MAPE----------\n",
      "Testing error: 11.96 %\n",
      "-----------MAE----------\n",
      "Testing error: 9.561396598815918\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 151.68it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-9389-07271242.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 158.48it/s]-----------MSE----------\n",
      "Testing error: 164.30648803710938\n",
      "-----------RMSE----------\n",
      "Testing error: 12.818209648132324\n",
      "-----------MAPE----------\n",
      "Testing error: 11.29 %\n",
      "-----------MAE----------\n",
      "Testing error: 9.106727600097656\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 146.45it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the models and evaluate them\n",
    "results = []\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "\n",
    "    # Load model checkpoint\n",
    "    checkpoint_dict = torch.load(model_name)\n",
    "    model = NodeEncodedGCN_1l(\n",
    "        transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "        weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "        lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "        drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "        batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "        input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "        hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "        aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    "    )\n",
    "    model = model.load_from_checkpoint(f'{model_name}')\n",
    "\n",
    "    trainer = pl.Trainer(gpus=1)\n",
    "    results.append(trainer.test(model, datamodule=data_module, verbose=False))\n",
    "\n",
    "# Print the results\n",
    "mse_arr = np.array([run_dict[0]['test/error_mse'] for run_dict in results])\n",
    "mae_arr = np.array([run_dict[0]['test/error_mae'] for run_dict in results])\n",
    "mape_arr = np.array([run_dict[0]['test/error_mape'] for run_dict in results])\n",
    "rmse_arr = np.array([run_dict[0]['test/error_rmse'] for run_dict in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for TAMPERE_FINAL with <class 'data.datamodule.MaxMin'> transform and travel_times time kind\n",
      "MSE: 168.2851219177246 +/- 2.5258853070496516\n",
      "MAE: 9.319565534591675 +/- 0.18882532996466594\n",
      "RMSE: 12.972108364105225 +/- 0.09759443783106886\n"
     ]
    }
   ],
   "source": [
    "print(f'Results for {site_name} with {type(transform)} transform and {time_kind} time kind')\n",
    "print(f'MSE: {mse_arr.mean()} +/- {mse_arr.std()}')\n",
    "print(f'MAE: {mae_arr.mean()} +/- {mae_arr.std()}')\n",
    "print(f'RMSE: {rmse_arr.mean()} +/- {rmse_arr.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-9389-07271242.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 75.05it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fea7f5f5be0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = model_names[np.argmin(mse_arr)]\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint_dict = torch.load(best_model)\n",
    "model = NodeEncodedGCN_1l(\n",
    "    transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "    weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "    lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "    drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "    batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "    input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "    hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "    aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    ")\n",
    "model = model.load_from_checkpoint(f'{best_model}')\n",
    "\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "output = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
    "y_hat = np.concatenate([out[0] for out in output])\n",
    "y_true = np.concatenate([out[1] for out in output])\n",
    "\n",
    "df = pd.DataFrame({'y_true': y_true, 'y_hat': y_hat, 'date': data_module.test_dates})\n",
    "df.to_csv(f'{best_model}_pred.csv', index=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(y_true, bins=100, alpha=0.75)\n",
    "ax.hist(y_hat, bins=100, alpha=0.75)\n",
    "ax.legend(['y_true', 'y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "show_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
