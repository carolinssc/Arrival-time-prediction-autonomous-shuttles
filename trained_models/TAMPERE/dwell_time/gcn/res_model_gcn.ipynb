{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../../src')\n",
    "import os\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from data.datamodule import SHOWDataModule\n",
    "from models.gcn_model import NodeEncodedGCN, NodeEncodedGCN_tt, NodeEncodedGCN_1l, NodeEncodedGCN_2l, NodeEncodedGCN_3l\n",
    "\n",
    "\n",
    "def simple_model_evaluation(y_test, y_pred_test):\n",
    "    # Simple model evaluation that computes and prints MSE, RMSE and MAPE for the training and testing set\n",
    "\n",
    "    # train_error_mse = np.square(y_train - y_pred_train).sum() / y_train.shape[0]\n",
    "    test_error_mse = np.square(y_test - y_pred_test).sum() / y_test.shape[0]\n",
    "\n",
    "    # train_error_mape = (100 / y_train.shape[0]) * (\n",
    "    #    np.absolute(y_train - y_pred_train) / y_train\n",
    "    # ).sum()  # y_train should never be 0 since the travel time in a segment cannot be 0\n",
    "    test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
    "\n",
    "    test_error_mae = (1 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test)).sum()\n",
    "    print(\"-----------MSE----------\")\n",
    "    # print(\"Training error: {}\".format(train_error_mse))\n",
    "    print(\"Testing error: {}\".format(test_error_mse))\n",
    "    print(\"-----------RMSE----------\")\n",
    "    # print(\"Training error: {}\".format(np.sqrt(train_error_mse)))\n",
    "    print(\"Testing error: {}\".format(np.sqrt(test_error_mse)))\n",
    "    print(\"-----------MAPE----------\")\n",
    "    # print(\"Training error: {:.2f} %\".format(train_error_mape))\n",
    "    print(\"Testing error: {:.2f} %\".format(test_error_mape))\n",
    "    print(\"-----------MAE----------\")\n",
    "    print(\"Testing error: {}\".format(test_error_mae))\n",
    "    return test_error_mse, np.sqrt(test_error_mse), test_error_mape, test_error_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the checkpoint directory\n",
    "checkpoint_dir = '.'\n",
    "model_names = os.listdir(checkpoint_dir)\n",
    "\n",
    "# remove all files not ending on ckpt\n",
    "model_names = [model_name for model_name in model_names if model_name.endswith('ckpt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ne_gcn-9480-07271139.ckpt',\n",
       " 'ne_gcn-1258-07271139.ckpt',\n",
       " 'ne_gcn-3367-07271139.ckpt',\n",
       " 'ne_gcn-6855-07271139.ckpt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the datamodule\n",
    "site_name = 'TAMPERE_FINAL'\n",
    "transform = 'maxmin'\n",
    "batch_size = 64\n",
    "empty_graph = False\n",
    "time_kind = 'dwell_times'\n",
    "data_module = SHOWDataModule(\n",
    "    site_name=site_name,\n",
    "    transform=transform,\n",
    "    num_lags=2,\n",
    "    train_frac=0.9,\n",
    "    batch_size=batch_size,\n",
    "    empty_graph=empty_graph,\n",
    "    verbose=False,\n",
    "    time_kind=time_kind,\n",
    ")\n",
    "transform = data_module.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-9480-07271139.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 145.87it/s]-----------MSE----------\n",
      "Testing error: 189.95155334472656\n",
      "-----------RMSE----------\n",
      "Testing error: 13.782291412353516\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 8.104964256286621\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 135.30it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-1258-07271139.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 124.84it/s]-----------MSE----------\n",
      "Testing error: 190.55238342285156\n",
      "-----------RMSE----------\n",
      "Testing error: 13.804071426391602\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 8.119331359863281\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 111.44it/s]\n",
      "ne_gcn-3367-07271139.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 139.72it/s]-----------MSE----------\n",
      "Testing error: 186.82115173339844\n",
      "-----------RMSE----------\n",
      "Testing error: 13.668253898620605\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 8.160200119018555\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 130.26it/s]\n",
      "ne_gcn-6855-07271139.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 115.56it/s]-----------MSE----------\n",
      "Testing error: 184.0148162841797\n",
      "-----------RMSE----------\n",
      "Testing error: 13.565206527709961\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 8.147924423217773\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 104.41it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the models and evaluate them\n",
    "results = []\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "\n",
    "    # Load model checkpoint\n",
    "    checkpoint_dict = torch.load(model_name)\n",
    "    model = NodeEncodedGCN_1l(\n",
    "        transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "        weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "        lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "        drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "        batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "        input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "        hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "        aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    "    )\n",
    "    model = model.load_from_checkpoint(f'{model_name}')\n",
    "\n",
    "    trainer = pl.Trainer(gpus=1)\n",
    "    results.append(trainer.test(model, datamodule=data_module, verbose=False))\n",
    "\n",
    "# Print the results\n",
    "mse_arr = np.array([run_dict[0]['test/error_mse'] for run_dict in results])\n",
    "mae_arr = np.array([run_dict[0]['test/error_mae'] for run_dict in results])\n",
    "mape_arr = np.array([run_dict[0]['test/error_mape'] for run_dict in results])\n",
    "rmse_arr = np.array([run_dict[0]['test/error_rmse'] for run_dict in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for TAMPERE_FINAL with <class 'data.datamodule.MaxMin'> transform and dwell_times time kind\n",
      "MSE: 187.83497619628906 +/- 2.621338525253124\n",
      "MAE: 8.133105039596558 +/- 0.021996450841492356\n",
      "RMSE: 13.704955816268921 +/- 0.09576219635580369\n"
     ]
    }
   ],
   "source": [
    "print(f'Results for {site_name} with {type(transform)} transform and {time_kind} time kind')\n",
    "print(f'MSE: {mse_arr.mean()} +/- {mse_arr.std()}')\n",
    "print(f'MAE: {mae_arr.mean()} +/- {mae_arr.std()}')\n",
    "print(f'RMSE: {rmse_arr.mean()} +/- {rmse_arr.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-6855-07271139.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 63.42it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f97825bb4f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = model_names[np.argmin(mse_arr)]\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint_dict = torch.load(best_model)\n",
    "model = NodeEncodedGCN_1l(\n",
    "    transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "    weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "    lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "    drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "    batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "    input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "    hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "    aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    ")\n",
    "model = model.load_from_checkpoint(f'{best_model}')\n",
    "\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "output = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
    "y_hat = np.concatenate([out[0] for out in output])\n",
    "y_true = np.concatenate([out[1] for out in output])\n",
    "\n",
    "df = pd.DataFrame({'y_true': y_true, 'y_hat': y_hat})\n",
    "df.to_csv(f'{best_model}_pred.csv', index=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(y_true, bins=100, alpha=0.75)\n",
    "ax.hist(y_hat, bins=100, alpha=0.75)\n",
    "ax.legend(['y_true', 'y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "show_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
