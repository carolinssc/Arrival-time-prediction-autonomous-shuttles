{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../../src')\n",
    "import os\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from data.datamodule import SHOWDataModule\n",
    "from models.gcn_model import NodeEncodedGCN, NodeEncodedGCN_tt, NodeEncodedGCN_1l, NodeEncodedGCN_2l, NodeEncodedGCN_3l\n",
    "\n",
    "\n",
    "def simple_model_evaluation(y_test, y_pred_test):\n",
    "    # Simple model evaluation that computes and prints MSE, RMSE and MAPE for the training and testing set\n",
    "\n",
    "    # train_error_mse = np.square(y_train - y_pred_train).sum() / y_train.shape[0]\n",
    "    test_error_mse = np.square(y_test - y_pred_test).sum() / y_test.shape[0]\n",
    "\n",
    "    # train_error_mape = (100 / y_train.shape[0]) * (\n",
    "    #    np.absolute(y_train - y_pred_train) / y_train\n",
    "    # ).sum()  # y_train should never be 0 since the travel time in a segment cannot be 0\n",
    "    test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
    "\n",
    "    test_error_mae = (1 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test)).sum()\n",
    "    print(\"-----------MSE----------\")\n",
    "    # print(\"Training error: {}\".format(train_error_mse))\n",
    "    print(\"Testing error: {}\".format(test_error_mse))\n",
    "    print(\"-----------RMSE----------\")\n",
    "    # print(\"Training error: {}\".format(np.sqrt(train_error_mse)))\n",
    "    print(\"Testing error: {}\".format(np.sqrt(test_error_mse)))\n",
    "    print(\"-----------MAPE----------\")\n",
    "    # print(\"Training error: {:.2f} %\".format(train_error_mape))\n",
    "    print(\"Testing error: {:.2f} %\".format(test_error_mape))\n",
    "    print(\"-----------MAE----------\")\n",
    "    print(\"Testing error: {}\".format(test_error_mae))\n",
    "    return test_error_mse, np.sqrt(test_error_mse), test_error_mape, test_error_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Removing zero obs based on RF classifier ***\n",
      "Confusion matrix train: [2585    0    0 3343]\n",
      "Confusion matrix test: [265 111  72 320]\n"
     ]
    }
   ],
   "source": [
    "# Path for the checkpoint directory\n",
    "\n",
    "# Load the datamodule\n",
    "site_name = 'TAMPERE_FINAL'\n",
    "transform_type = 'maxmin'\n",
    "batch_size = 64\n",
    "empty_graph = False\n",
    "time_kind = 'dwell_times'\n",
    "data_module = SHOWDataModule(\n",
    "    site_name=site_name,\n",
    "    transform=transform_type,\n",
    "    num_lags=2,\n",
    "    train_frac=0.9,\n",
    "    batch_size=batch_size,\n",
    "    empty_graph=empty_graph,\n",
    "    verbose=False,\n",
    "    time_kind=time_kind,\n",
    ")\n",
    "transform = data_module.setup()\n",
    "\n",
    "data_module_rf = SHOWDataModule(\n",
    "    site_name=site_name,\n",
    "    transform=transform_type,\n",
    "    num_lags=2,\n",
    "    train_frac=0.9,\n",
    "    batch_size=batch_size,\n",
    "    empty_graph=empty_graph,\n",
    "    verbose=False,\n",
    "    time_kind=time_kind,\n",
    "    rf_remove_zero_obs=True,\n",
    "    \n",
    ")\n",
    "transform_rf = data_module_rf.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = os.listdir('.')\n",
    "# remove any files that don't end with .ckpt\n",
    "model_names = [name for name in model_names if name.endswith('.ckpt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ne_gcn-5124-07271142.ckpt',\n",
       " 'ne_gcn-4239-07271142.ckpt',\n",
       " 'ne_gcn-6105-07271142.ckpt',\n",
       " 'ne_gcn-9788-07271142.ckpt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-5124-07271142.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_659032/205311161.py:24: RuntimeWarning: divide by zero encountered in divide\n",
      "  test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
      "/tmp/ipykernel_659032/205311161.py:24: RuntimeWarning: invalid value encountered in divide\n",
      "  test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****BEFORE RF ZERO FIXING****\n",
      "-----------MSE----------\n",
      "Testing error: 201.42118326822916\n",
      "-----------RMSE----------\n",
      "Testing error: 14.192293094078531\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 11.50912348429362\n",
      "*****************************\n",
      " *** AFTER RF ZERO FIXING ****\n",
      "-----------MSE----------\n",
      "Testing error: 161.6777140299479\n",
      "-----------RMSE----------\n",
      "Testing error: 12.715255169675043\n",
      "-----------MAPE----------\n",
      "Testing error: nan %\n",
      "-----------MAE----------\n",
      "Testing error: 7.6587982177734375\n",
      "*****************************\n",
      "ne_gcn-4239-07271142.ckpt\n",
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 55.84it/s] \n",
      "****BEFORE RF ZERO FIXING****\n",
      "-----------MSE----------\n",
      "Testing error: 197.165771484375\n",
      "-----------RMSE----------\n",
      "Testing error: 14.041572970446545\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 11.349886576334635\n",
      "*****************************\n",
      " *** AFTER RF ZERO FIXING ****\n",
      "-----------MSE----------\n",
      "Testing error: 161.06620279947916\n",
      "-----------RMSE----------\n",
      "Testing error: 12.691186028085758\n",
      "-----------MAPE----------\n",
      "Testing error: nan %\n",
      "-----------MAE----------\n",
      "Testing error: 7.634818394978841\n",
      "*****************************\n",
      "ne_gcn-6105-07271142.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 62.39it/s] \n",
      "****BEFORE RF ZERO FIXING****\n",
      "-----------MSE----------\n",
      "Testing error: 197.40608723958334\n",
      "-----------RMSE----------\n",
      "Testing error: 14.05012765919169\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 11.352307637532551\n",
      "*****************************\n",
      " *** AFTER RF ZERO FIXING ****\n",
      "-----------MSE----------\n",
      "Testing error: 161.21728515625\n",
      "-----------RMSE----------\n",
      "Testing error: 12.697136888143326\n",
      "-----------MAPE----------\n",
      "Testing error: nan %\n",
      "-----------MAE----------\n",
      "Testing error: 7.6663576761881504\n",
      "*****************************\n",
      "ne_gcn-9788-07271142.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 55.71it/s] \n",
      "****BEFORE RF ZERO FIXING****\n",
      "-----------MSE----------\n",
      "Testing error: 194.2611287434896\n",
      "-----------RMSE----------\n",
      "Testing error: 13.937759100497095\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 11.148255666097004\n",
      "*****************************\n",
      " *** AFTER RF ZERO FIXING ****\n",
      "-----------MSE----------\n",
      "Testing error: 164.15243530273438\n",
      "-----------RMSE----------\n",
      "Testing error: 12.812198691197947\n",
      "-----------MAPE----------\n",
      "Testing error: nan %\n",
      "-----------MAE----------\n",
      "Testing error: 7.659528096516927\n",
      "*****************************\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# Load model checkpoint\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    checkpoint_dict = torch.load(model_name)\n",
    "    model = NodeEncodedGCN_1l(\n",
    "        transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "        weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "        lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "        drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "        batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "        input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "        hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "        aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    "    )\n",
    "    model = model.load_from_checkpoint(model_name)\n",
    "\n",
    "    trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "    output = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
    "    y_hat = np.concatenate([out[0] for out in output])\n",
    "    y_true = np.concatenate([out[1] for out in output])\n",
    "\n",
    "    #df = pd.DataFrame({'y_true': y_true, 'y_hat': y_hat})\n",
    "    #df.to_csv(f'{model_name}_pred.csv', index=False)\n",
    "\n",
    "    print('****BEFORE RF ZERO FIXING****')\n",
    "    simple_model_evaluation(y_true, y_hat)\n",
    "    print('*****************************')\n",
    "\n",
    "    y_hat_rf = np.zeros_like(y_hat)\n",
    "    y_hat_rf[data_module_rf.non_zero_indices_test] = y_hat[data_module_rf.non_zero_indices_test]\n",
    "    print(' *** AFTER RF ZERO FIXING ****')\n",
    "    temp_res = simple_model_evaluation(y_hat_rf, y_true)\n",
    "    results.append(temp_res)\n",
    "    print('*****************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n",
    "mse_arr = np.array([res[0] for res in results])\n",
    "rmse_arr = np.array([res[1] for res in results])\n",
    "mape_arr = np.array([res[2] for res in results])\n",
    "mae_arr = np.array([res[3] for res in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for TAMPERE_FINAL with <class 'data.datamodule.MaxMin'> transform and dwell_times time kind\n",
      "MSE: 162.02840932210285 +/- 1.2468196901464355\n",
      "MAE: 7.654875596364339 +/- 0.011949499998825832\n",
      "RMSE: 12.728944194275519 +/- 0.04887761371456187\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Results for {site_name} with {type(transform)} transform and {time_kind} time kind')\n",
    "print(f'MSE: {mse_arr.mean()} +/- {mse_arr.std()}')\n",
    "print(f'MAE: {mae_arr.mean()} +/- {mae_arr.std()}')\n",
    "print(f'RMSE: {rmse_arr.mean()} +/- {rmse_arr.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_idx = np.argmin(mse_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 55.53it/s] \n",
      "****BEFORE RF ZERO FIXING****\n",
      "-----------MSE----------\n",
      "Testing error: 197.165771484375\n",
      "-----------RMSE----------\n",
      "Testing error: 14.041572970446545\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 11.349886576334635\n",
      "*****************************\n",
      " *** AFTER RF ZERO FIXING ****\n",
      "-----------MSE----------\n",
      "Testing error: 161.06620279947916\n",
      "-----------RMSE----------\n",
      "Testing error: 12.691186028085758\n",
      "-----------MAPE----------\n",
      "Testing error: nan %\n",
      "-----------MAE----------\n",
      "Testing error: 7.634818394978841\n",
      "*****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_659032/205311161.py:24: RuntimeWarning: divide by zero encountered in divide\n",
      "  test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
      "/tmp/ipykernel_659032/205311161.py:24: RuntimeWarning: invalid value encountered in divide\n",
      "  test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n"
     ]
    }
   ],
   "source": [
    "model_name = model_names[best_model_idx]\n",
    "checkpoint_dict = torch.load(model_name)\n",
    "model = NodeEncodedGCN_1l(\n",
    "    transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "    weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "    lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "    drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "    batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "    input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "    hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "    aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    ")\n",
    "model = model.load_from_checkpoint(model_name)\n",
    "\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "output = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
    "y_hat = np.concatenate([out[0] for out in output])\n",
    "y_true = np.concatenate([out[1] for out in output])\n",
    "\n",
    "\n",
    "print('****BEFORE RF ZERO FIXING****')\n",
    "simple_model_evaluation(y_true, y_hat)\n",
    "print('*****************************')\n",
    "\n",
    "y_hat_rf = np.zeros_like(y_hat)\n",
    "y_hat_rf[data_module_rf.non_zero_indices_test] = y_hat[data_module_rf.non_zero_indices_test]\n",
    "print(' *** AFTER RF ZERO FIXING ****')\n",
    "temp_res = simple_model_evaluation(y_hat_rf, y_true)\n",
    "results.append(temp_res)\n",
    "print('*****************************')\n",
    "\n",
    "df = pd.DataFrame({'y_true': y_true, 'y_hat': y_hat_rf, 'date': data_module.test_dates})\n",
    "df.to_csv(f'{model_name}_pred.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f98fed0e340>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyeUlEQVR4nO3de1hWdb7//xdnQb1vAoUbEhCr8YSntOiecraTJHmoKPLKdExH0ysHO7HHzHaZ2jbU2juzy0O6J8kph5n6lRWWpjhS7UjTPaZiMelgmnpDJ7gVR0BYvz8c1rdbQTnfC3w+rmtdF+uzPmut92J1yavPOvkYhmEIAADAQny9XQAAAMD5CCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMByCCgAAMBy/L1dQGNUV1fr+PHj6ty5s3x8fLxdDgAAqAfDMHTy5ElFR0fL1/fiYyRtMqAcP35cMTEx3i4DAAA0wtGjR9WtW7eL9mmTAaVz586Szh2gzWbzcjUAAKA+3G63YmJizL/jF9MmA0rNZR2bzUZAAQCgjanP7RncJAsAACyHgAIAACyHgAIAACynTd6DAgC4fBmGobNnz6qqqsrbpeA8fn5+8vf3b5ZXgBBQAABtRkVFhU6cOKHTp097uxTUISQkRFFRUQoMDGzSdggoAIA2obq6WoWFhfLz81N0dLQCAwN5WaeFGIahiooKfffddyosLNQ111xzyZexXQwBBQDQJlRUVKi6uloxMTEKCQnxdjmoRXBwsAICAvTNN9+ooqJCHTp0aPS2uEkWANCmNOX/ytHymuv8cJYBAIDlEFAAAIDlcA8KAKDNG7c6r1X3lzXd2ar7uxwxggIAgEXNmzdPAwcO9HYZXkFAAQCgjausrPR2Cc2OgAIAQAtat26dwsPDVV5e7tGekpKiiRMn1rleZmam5s+fry+++EI+Pj7y8fFRZmampHNfA165cqVuv/12dezYUQsXLlRmZqZCQ0M9trFhw4YL3hXzzjvv6Nprr1WHDh3Uo0cPzZ8/X2fPnm2WY21O3INSi/OvZXKtEQDQWGPHjtVDDz2kd999V2PHjpUkFRcXa+PGjfrwww/rXO+ee+7R/v37tWnTJm3dulWSZLfbzeXz5s3TokWLtHTpUvn7+2vbtm2XrOXjjz/Wfffdp2XLlmno0KE6dOiQpk+fLkl6+umnm3KYzY4RFAAAWlBwcLDGjx+vtWvXmm2vvfaaYmNjNWzYsIuu16lTJ/n7+8vhcMjhcCg4ONhcPn78eP32t79Vjx49FBsbW69a5s+fr8cff1yTJk1Sjx49dMstt+iZZ57Ryy+/3OjjaymMoAAA0MKmTZum6667TseOHdOVV16pzMxMTZ48uUmv6h8yZEiD1/niiy/0v//7v1q4cKHZVlVVpTNnzuj06dOWekMvAQUAgBY2aNAgDRgwQOvWrdOIESOUn5+vjRs3NmmbHTt29Jj39fWVYRgebeffPHvq1CnNnz9fd9111wXba8pr6VsCAQUAgFZw//33a+nSpTp27JiSkpIUExNzyXUCAwNVVVVVr+137dpVJ0+eVFlZmRle9uzZ49Hn2muvVUFBga6++uoG19/auAcFAIBWMH78eH377bdas2aNpkyZUq91unfvrsLCQu3Zs0fff//9BU8C/VxiYqJCQkL0xBNP6NChQ1q/fr351E+NuXPnat26dZo/f77y8/P15ZdfKisrS08++WRTDq1FMIICAGjz2sLTlna7Xampqdq4caNSUlLqtU5qaqreeust/frXv1ZJSYnWrl2ryZMn19o3LCxMr732mmbNmqU1a9Zo+PDhmjdvnvmUjiQlJycrOztbCxYs0OLFixUQEKBevXrp/vvvb4YjbF4EFAAAWsmxY8c0YcIEBQUF1at/UFCQ3nzzzQvaz7/XpEZKSsoF4WfatGke88nJyUpOTq5fwV5EQAEAoIX99NNP2r59u7Zv364VK1Z4u5w2gYACAEALGzRokH766SctXrxYPXv2NNv79u2rb775ptZ1Xn75ZU2YMKG1SrQcAgoAAC3s8OHDtba///77dX5HJzIysgUrsj4CCgAAXhIXF+ftEiyLx4wBAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAALCoefPmaeDAgd4uwyt4zBgA0PZljmnd/U3Obt39NcHhw4cVHx+vv/3tb20q7DCCAgAALKdBAWXlypXq37+/bDabbDabnE6nPvjgA3P5sGHD5OPj4zE98MADHts4cuSIRo8erZCQEEVERGjWrFk6e/Zs8xwNAAAWs27dOoWHh6u8vNyjPSUlRRMnTqzXNv74xz+qe/fustvtGjdunE6ePGku27Rpk2666SaFhoYqPDxcY8aM0aFDh8zl8fHxks69bt/Hx0fDhg1r+kG1ggYFlG7dumnRokXavXu3du3apZtvvll33HGH8vPzzT7Tpk3TiRMnzGnJkiXmsqqqKo0ePVoVFRX69NNP9eqrryozM1Nz585tviMCAMBCxo4dq6qqKr377rtmW3FxsTZu3KgpU6Zccv1Dhw5pw4YNys7OVnZ2tnJzc7Vo0SJzeVlZmdLT07Vr1y7l5OTI19dXd955p6qrqyVJO3fulCRt3bpVJ06c0FtvvdXMR9gyGnQPym233eYxv3DhQq1cuVKfffaZ+vbtK0kKCQmRw+Godf0PP/xQBw4c0NatWxUZGamBAwfqmWee0ezZszVv3jwFBgY28jAAALCm4OBgjR8/XmvXrtXYsWMlSa+99ppiY2PrNZpRXV2tzMxMde7cWZI0ceJE5eTkaOHChZKk1NRUj/6vvPKKunbtqgMHDighIUFdu3aVJIWHh9f599mKGn0PSlVVlbKyslRWVian02m2v/766+rSpYsSEhI0Z84cnT592lyWl5enfv36eXwAKTk5WW6322MUBgCA9mTatGn68MMPdezYMUlSZmamJk+eLB8fn0uu2717dzOcSFJUVJSKi4vN+a+//lr33nuvevToIZvNpu7du0s6d0tFW9bgp3j27dsnp9OpM2fOqFOnTnr77bfVp08fSdL48eMVFxen6Oho7d27V7Nnz1ZBQYE5nORyuS74OmPNvMvlqnOf5eXlHtfu3G53Q8sGAMBrBg0apAEDBmjdunUaMWKE8vPztXHjxnqtGxAQ4DHv4+NjXr6Rzl3diIuL05o1axQdHa3q6molJCSooqKiWY+htTU4oPTs2VN79uxRaWmp3nzzTU2aNEm5ubnq06ePpk+fbvbr16+foqKiNHz4cB06dEhXXXVVo4vMyMjQ/PnzG70+AADedv/992vp0qU6duyYkpKSFBMT0+Rt/vDDDyooKNCaNWs0dOhQSdInn3zi0afm9omqqqom7681NfgST2BgoK6++moNHjxYGRkZGjBggF588cVa+yYmJkqSDh48KElyOBwqKiry6FMzf7HrYnPmzFFpaak5HT16tKFlAwDgVePHj9e3336rNWvW1Ovm2Pq44oorFB4ertWrV+vgwYPatm2b0tPTPfpEREQoODhYmzZtUlFRkUpLS5tl3y2tyS9qq66uvuDRqRp79uyRdO56mSQ5nU4tXLhQxcXFioiIkCRt2bJFNpvNvExUm6CgIAUFBTW1VABAe9UGXpxmt9uVmpqqjRs3KiUlpVm26evrq6ysLD300ENKSEhQz549tWzZMo+bb/39/bVs2TItWLBAc+fO1dChQ7V9+/Zm2X9L8jEMw6hv5zlz5mjkyJGKjY3VyZMntX79ei1evFibN29Wjx49tH79eo0aNUrh4eHau3evHn30UXXr1k25ubmSzg0vDRw4UNHR0VqyZIlcLpcmTpyo+++/X88++2y9i3a73bLb7SotLZXNZmv4UV/CuNV5HvNZ05119AQAtJYzZ86osLBQ8fHx6tChg7fLaZThw4erb9++WrZsmbdLaTEXO08N+fvdoBGU4uJi3XfffTpx4oTsdrv69++vzZs365ZbbtHRo0e1detWLV26VGVlZYqJiVFqaqqefPJJc30/Pz9lZ2drxowZcjqd6tixoyZNmqQFCxY0pAwAANqUn376Sdu3b9f27du1YsUKb5fTJjQooPzhD3+oc1lMTIw5UnIxcXFxev/99xuyWwAA2rRBgwbpp59+0uLFi9WzZ0+zvW/fvvrmm29qXefll1/WhAkTWqtEy+FjgQAAtLDDhw/X2v7++++rsrKy1mXnv5bjckNAAQDAS+Li4rxdgmXxNWMAAGA5BBQAAGA5BBQAAGA5BBQAAGA5BJRaFAY87+0SAAC4rBFQAACwqHnz5mngwIHeLsN0+vRppaamymazycfHRyUlJS22Lx4zBgC0eVM2N8/H9+rrleRXWnV/TXH48GHFx8frb3/7W5PDzquvvqqPP/5Yn376qbp06SK73d48RdaCgAIAAC6qoqJCgYGBOnTokHr37q2EhIQW3yeXeAAAaEHr1q1TeHi4ysvLPdpTUlI0ceLEem3jj3/8o7p37y673a5x48bp5MmT5rJNmzbppptuUmhoqMLDwzVmzBgdOnTIXB4fHy/p3Ov2fXx8PL50XJfJkycrJSVFCxcuVHR0tHr27Klhw4bpv/7rv/TRRx/VeztNQUABAKAFjR07VlVVVXr33XfNtuLiYm3cuFFTplz60tShQ4e0YcMGZWdnKzs7W7m5uVq0aJG5vKysTOnp6dq1a5dycnLk6+urO++8U9XV1ZKknTt3SpK2bt2qEydO6K233qpX3Tk5OSooKNCWLVuUnZ2tt956S9OmTZPT6WzQdhqLSzwAALSg4OBgjR8/XmvXrtXYsWMlSa+99ppiY2PrNQpRXV2tzMxMde7cWZI0ceJE5eTkaOHChZKk1NRUj/6vvPKKunbtqgMHDighIUFdu3aVJIWHh8vhcNS77o4dO+p//ud/FBgYaLaFhIQoMDCwQdtpLEZQAABoYdOmTdOHH36oY8eOSZIyMzM1efJk+fj4XHLd7t27m+FEkqKiolRcXGzOf/3117r33nvVo0cP2Ww2de/eXZJ05MiRJtXcr18/j3DS2hhBAQCghQ0aNEgDBgzQunXrNGLECOXn52vjxo31WjcgIMBj3sfHx7x8I0m33Xab4uLitGbNGkVHR6u6uloJCQmqqKhoUs0dO3Zs0vpNRUABAKAV3H///Vq6dKmOHTumpKQkxcTENHmbP/zwgwoKCrRmzRoNHTpUkvTJJ5949KkZBamqqmry/loTl3gAAGgF48eP17fffqs1a9bU6+bY+rjiiisUHh6u1atX6+DBg9q2bZvS09M9+kRERCg4OFibNm1SUVGRSktLm2XfLY0RFABAm9cWXpxmt9uVmpqqjRs3KiUlpVm26evrq6ysLD300ENKSEhQz549tWzZMo+bb/39/bVs2TItWLBAc+fO1dChQ7V9+/Zm2X9L8jEMw/B2EQ3ldrtlt9tVWloqm83W7NtPXJuq+Mrfm/NZ053Nvg8AQMOcOXNGhYWFio+PV4cOHbxdTqMMHz5cffv21bJly7xdSou52HlqyN9vRlAAAGhhP/30k7Zv367t27drxYoV3i6nTSCgAADQwgYNGqSffvpJixcvVs+ePc32vn376ptvvql1nZdfflkTJkxokXo6depU57IPPvjAvOHWmwgoAAC0sMOHD9fa/v7776uysrLWZZGRkS1Wz549e+pcduWVV7bYfhuCgAIAgJfExcV5Zb9XX321V/bbEDxmDABoU9rgsx2XleY6PwQUAECbUPNG1dOnT3u5ElxMzfk5/w24DcUlHgBAm+Dn56fQ0FDzOzQhISH1+pYNWodhGDp9+rSKi4sVGhoqPz+/Jm2PgAIAaDNqvqL784/lwVpCQ0Ob5WvHBBQAQJvh4+OjqKgoRURE1Pn0C7wnICCgySMnNQgoAIA2x8/Pr9n+EMKauEkWAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYDgEFAABYToMCysqVK9W/f3/ZbDbZbDY5nU598MEH5vIzZ84oLS1N4eHh6tSpk1JTU1VUVOSxjSNHjmj06NEKCQlRRESEZs2apbNnzzbP0QAAgHahQQGlW7duWrRokXbv3q1du3bp5ptv1h133KH8/HxJ0qOPPqr33ntPb7zxhnJzc3X8+HHddddd5vpVVVUaPXq0Kioq9Omnn+rVV19VZmam5s6d27xHBQAA2jQfo4nfRQ4LC9Nzzz2nu+++W127dtX69et19913S5K++uor9e7dW3l5ebrhhhv0wQcfaMyYMTp+/LgiIyMlSatWrdLs2bP13XffKTAwsF77dLvdstvtKi0tlc1ma0r5tUpcm6r4yt+b81nTnc2+DwAALjcN+fvd6HtQqqqqlJWVpbKyMjmdTu3evVuVlZVKSkoy+/Tq1UuxsbHKy8uTJOXl5alfv35mOJGk5ORkud1ucxSmNuXl5XK73R4TAABovxocUPbt26dOnTopKChIDzzwgN5++2316dNHLpdLgYGBCg0N9egfGRkpl8slSXK5XB7hpGZ5zbK6ZGRkyG63m1NMTExDywYAAG1IgwNKz549tWfPHu3YsUMzZszQpEmTdODAgZaozTRnzhyVlpaa09GjR1t0fwAAwLsa/DXjwMBAXX311ZKkwYMH6/PPP9eLL76oe+65RxUVFSopKfEYRSkqKpLD4ZAkORwO7dy502N7NU/51PSpTVBQkIKCghpaKgAAaKOa/B6U6upqlZeXa/DgwQoICFBOTo65rKCgQEeOHJHTee4mU6fTqX379qm4uNjss2XLFtlsNvXp06eppQAAgHaiQSMoc+bM0ciRIxUbG6uTJ09q/fr12r59uzZv3iy73a6pU6cqPT1dYWFhstlsevDBB+V0OnXDDTdIkkaMGKE+ffpo4sSJWrJkiVwul5588kmlpaUxQgIAAEwNCijFxcW67777dOLECdntdvXv31+bN2/WLbfcIkl64YUX5Ovrq9TUVJWXlys5OVkrVqww1/fz81N2drZmzJghp9Opjh07atKkSVqwYEHzHhUAAGjTmvweFG/gPSgAALQ9rfIeFAAAgJZCQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJbToICSkZGh6667Tp07d1ZERIRSUlJUUFDg0WfYsGHy8fHxmB544AGPPkeOHNHo0aMVEhKiiIgIzZo1S2fPnm360QAAgHbBvyGdc3NzlZaWpuuuu05nz57VE088oREjRujAgQPq2LGj2W/atGlasGCBOR8SEmL+XFVVpdGjR8vhcOjTTz/ViRMndN999ykgIEDPPvtsMxwSAABo6xoUUDZt2uQxn5mZqYiICO3evVu/+tWvzPaQkBA5HI5at/Hhhx/qwIED2rp1qyIjIzVw4EA988wzmj17tubNm6fAwMBGHAYAAGhPmnQPSmlpqSQpLCzMo/31119Xly5dlJCQoDlz5uj06dPmsry8PPXr10+RkZFmW3Jystxut/Lz82vdT3l5udxut8cEAADarwaNoPxcdXW1HnnkEd14441KSEgw28ePH6+4uDhFR0dr7969mj17tgoKCvTWW29Jklwul0c4kWTOu1yuWveVkZGh+fPnN7ZUAADQxjQ6oKSlpWn//v365JNPPNqnT59u/tyvXz9FRUVp+PDhOnTokK666qpG7WvOnDlKT083591ut2JiYhpXOAAAsLxGXeKZOXOmsrOz9de//lXdunW7aN/ExERJ0sGDByVJDodDRUVFHn1q5uu6byUoKEg2m81jAgAA7VeDAophGJo5c6befvttbdu2TfHx8ZdcZ8+ePZKkqKgoSZLT6dS+fftUXFxs9tmyZYtsNpv69OnTkHIAAEA71aBLPGlpaVq/fr3eeecdde7c2bxnxG63Kzg4WIcOHdL69es1atQohYeHa+/evXr00Uf1q1/9Sv3795ckjRgxQn369NHEiRO1ZMkSuVwuPfnkk0pLS1NQUFDzHyEAAGhzGjSCsnLlSpWWlmrYsGGKiooypz//+c+SpMDAQG3dulUjRoxQr1699O///u9KTU3Ve++9Z27Dz89P2dnZ8vPzk9Pp1G9+8xvdd999Hu9NAQAAl7cGjaAYhnHR5TExMcrNzb3kduLi4vT+++83ZNcAAOAywrd4AACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5RBQAACA5TQooGRkZOi6665T586dFRERoZSUFBUUFHj0OXPmjNLS0hQeHq5OnTopNTVVRUVFHn2OHDmi0aNHKyQkRBEREZo1a5bOnj3b9KMBAADtQoMCSm5urtLS0vTZZ59py5Ytqqys1IgRI1RWVmb2efTRR/Xee+/pjTfeUG5uro4fP6677rrLXF5VVaXRo0eroqJCn376qV599VVlZmZq7ty5zXdUAACgTfMxDMNo7MrfffedIiIilJubq1/96lcqLS1V165dtX79et19992SpK+++kq9e/dWXl6ebrjhBn3wwQcaM2aMjh8/rsjISEnSqlWrNHv2bH333XcKDAy85H7dbrfsdrtKS0tls9kaW36dEtemKr7y9+Z81nRns+8DAIDLTUP+fjfpHpTS0lJJUlhYmCRp9+7dqqysVFJSktmnV69eio2NVV5eniQpLy9P/fr1M8OJJCUnJ8vtdis/P7/W/ZSXl8vtdntMAACg/Wp0QKmurtYjjzyiG2+8UQkJCZIkl8ulwMBAhYaGevSNjIyUy+Uy+/w8nNQsr1lWm4yMDNntdnOKiYlpbNkAAKANaHRASUtL0/79+5WVldWc9dRqzpw5Ki0tNaejR4+2+D4BAID3+DdmpZkzZyo7O1sfffSRunXrZrY7HA5VVFSopKTEYxSlqKhIDofD7LNz506P7dU85VPT53xBQUEKCgpqTKkAAKANatAIimEYmjlzpt5++21t27ZN8fHxHssHDx6sgIAA5eTkmG0FBQU6cuSInM5zN5o6nU7t27dPxcXFZp8tW7bIZrOpT58+TTkWAADQTjRoBCUtLU3r16/XO++8o86dO5v3jNjtdgUHB8tut2vq1KlKT09XWFiYbDabHnzwQTmdTt1www2SpBEjRqhPnz6aOHGilixZIpfLpSeffFJpaWmMkgAAAEkNDCgrV66UJA0bNsyjfe3atZo8ebIk6YUXXpCvr69SU1NVXl6u5ORkrVixwuzr5+en7OxszZgxQ06nUx07dtSkSZO0YMGCph0JAABoNxoUUOrzypQOHTpo+fLlWr58eZ194uLi9P777zdk1wAA4DLCt3gAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlEFAAAIDlNDigfPTRR7rtttsUHR0tHx8fbdiwwWP55MmT5ePj4zHdeuutHn1+/PFHTZgwQTabTaGhoZo6dapOnTrVpAMBAADtR4MDSllZmQYMGKDly5fX2efWW2/ViRMnzOlPf/qTx/IJEyYoPz9fW7ZsUXZ2tj766CNNnz694dUDAIB2yb+hK4wcOVIjR468aJ+goCA5HI5al3355ZfatGmTPv/8cw0ZMkSS9NJLL2nUqFF6/vnnFR0d3dCSAABAO9Mi96Bs375dERER6tmzp2bMmKEffvjBXJaXl6fQ0FAznEhSUlKSfH19tWPHjlq3V15eLrfb7TEBAID2q9kDyq233qp169YpJydHixcvVm5urkaOHKmqqipJksvlUkREhMc6/v7+CgsLk8vlqnWbGRkZstvt5hQTE9PcZQMAAAtp8CWeSxk3bpz5c79+/dS/f39dddVV2r59u4YPH96obc6ZM0fp6enmvNvtJqQAANCOtfhjxj169FCXLl108OBBSZLD4VBxcbFHn7Nnz+rHH3+s876VoKAg2Ww2jwkAALRfLR5Qvv32W/3www+KioqSJDmdTpWUlGj37t1mn23btqm6ulqJiYktXQ4AAGgDGnyJ59SpU+ZoiCQVFhZqz549CgsLU1hYmObPn6/U1FQ5HA4dOnRIjz32mK6++molJydLknr37q1bb71V06ZN06pVq1RZWamZM2dq3LhxPMEDAAAkNWIEZdeuXRo0aJAGDRokSUpPT9egQYM0d+5c+fn5ae/evbr99tv1i1/8QlOnTtXgwYP18ccfKygoyNzG66+/rl69emn48OEaNWqUbrrpJq1evbr5jgoAALRpDR5BGTZsmAzDqHP55s2bL7mNsLAwrV+/vqG7BgAAlwm+xQMAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACyHgAIAACynwQHlo48+0m233abo6Gj5+Phow4YNHssNw9DcuXMVFRWl4OBgJSUl6euvv/bo8+OPP2rChAmy2WwKDQ3V1KlTderUqSYdCAAAaD8aHFDKyso0YMAALV++vNblS5Ys0bJly7Rq1Srt2LFDHTt2VHJyss6cOWP2mTBhgvLz87VlyxZlZ2fro48+0vTp0xt/FAAAoF3xb+gKI0eO1MiRI2tdZhiGli5dqieffFJ33HGHJGndunWKjIzUhg0bNG7cOH355ZfatGmTPv/8cw0ZMkSS9NJLL2nUqFF6/vnnFR0d3YTDAQAA7UGz3oNSWFgol8ulpKQks81utysxMVF5eXmSpLy8PIWGhprhRJKSkpLk6+urHTt2NGc5AACgjWrwCMrFuFwuSVJkZKRHe2RkpLnM5XIpIiLCswh/f4WFhZl9zldeXq7y8nJz3u12N2fZAADAYtrEUzwZGRmy2+3mFBMT4+2SAABAC2rWgOJwOCRJRUVFHu1FRUXmMofDoeLiYo/lZ8+e1Y8//mj2Od+cOXNUWlpqTkePHm3OsgEAgMU0a0CJj4+Xw+FQTk6O2eZ2u7Vjxw45nU5JktPpVElJiXbv3m322bZtm6qrq5WYmFjrdoOCgmSz2TwmAADQfjX4HpRTp07p4MGD5nxhYaH27NmjsLAwxcbG6pFHHtF//ud/6pprrlF8fLyeeuopRUdHKyUlRZLUu3dv3XrrrZo2bZpWrVqlyspKzZw5U+PGjeMJHgAAIKkRAWXXrl369a9/bc6np6dLkiZNmqTMzEw99thjKisr0/Tp01VSUqKbbrpJmzZtUocOHcx1Xn/9dc2cOVPDhw+Xr6+vUlNTtWzZsmY4HAAA0B74GIZheLuIhnK73bLb7SotLW2Ryz2Ja1MVX/l7cz5rurPZ9wEAwOWmIX+/28RTPAAA4PJCQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJbT7AFl3rx58vHx8Zh69eplLj9z5ozS0tIUHh6uTp06KTU1VUVFRc1dBgAAaMNaZASlb9++OnHihDl98skn5rJHH31U7733nt544w3l5ubq+PHjuuuuu1qiDAAA0Eb5t8hG/f3lcDguaC8tLdUf/vAHrV+/XjfffLMkae3aterdu7c+++wz3XDDDS1RDgAAaGNaZATl66+/VnR0tHr06KEJEyboyJEjkqTdu3ersrJSSUlJZt9evXopNjZWeXl5dW6vvLxcbrfbYwIAAO1XsweUxMREZWZmatOmTVq5cqUKCws1dOhQnTx5Ui6XS4GBgQoNDfVYJzIyUi6Xq85tZmRkyG63m1NMTExzlw0AACyk2S/xjBw50vy5f//+SkxMVFxcnP7yl78oODi4UducM2eO0tPTzXm3201IAQCgHWvxx4xDQ0P1i1/8QgcPHpTD4VBFRYVKSko8+hQVFdV6z0qNoKAg2Ww2jwkAALRfLR5QTp06pUOHDikqKkqDBw9WQECAcnJyzOUFBQU6cuSInE5nS5cCAADaiGa/xPP73/9et912m+Li4nT8+HE9/fTT8vPz07333iu73a6pU6cqPT1dYWFhstlsevDBB+V0OnmCBwAAmJo9oHz77be699579cMPP6hr16666aab9Nlnn6lr166SpBdeeEG+vr5KTU1VeXm5kpOTtWLFiuYuAwAAtGHNHlCysrIuurxDhw5avny5li9f3ty7BgAA7QTf4gEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQAEAAJZDQGmvMsd4uwIAABqNgAIAACyHgAIAACzH39sFtBfjVudd0JY13emFSgAAaPsYQcGlZY7hnhYAQKsioAAAAMshoKBhGEkBALQCAgouDB2EEACAl3GTbCPVdlNsm5c5Rpqc7e0qAABgBAUAAFgPIyitqE09ilzbaErmGE2RS694pyIAwGWEgAJP/wohkggiAACv4RLP5ei8m2CnyKUpm6dcsl+9lwEA0ESMoHjZ+Zd9mnzJp45LM3Xe/Hpe0Lin4pj5c/73perbtGoAAGgURlBgqrm0U1t7XcskMZoCAGh2jKDUQ5t7pDhzjPKPl+qZ1Xl66vvHJEnPrM67+OjMib2tVBwAAJdGQGmrakYtmvDekimZQy7ZZ9zqPBmqknTukk9Zl6pG7as+TzC1qaecAAAtioDSglps5OUSl1SmyKWyLlXyqWW9c48JOxq12wVdTtW7ljY36gQAsBTuQWnHCgOeN3+uudRjqud9IxesJyn/2aHKP16qxLWpyj9eWvdTQAAANBIjKG3A+aMRT31fav78zL+WZU13XhA6ulf+Q1KnFq/ParhUBABtHwHlMlBzaebPsnu0l1Vc/H6SBV1Oae73Fwacmu11rzwlqZPKKqp0+Hhpq1zWIXwAwOWBgGIxjf0jP251np76vrT2+0RawbnRmgsVBjyv7pX/kI9WtHJFAIC2jIDSRpiPC3dZUq/21tKUQFQTxp76/rE66+dmWwC4PBFQ2onabmaVmhYgGrr+z2uoK3DUFagKA55XfOXvG1Gh9TT724EB4DLEUzwWVVfgqKu9PmreBnvJN8M2QUMCjaHftUgNAIC2z6sjKMuXL9dzzz0nl8ulAQMG6KWXXtL111/vzZLahLpuXvW2mnCyoMspHf7XiMj596bU9Dkc8Ly6V/6/wFXXPSw1arsMdLFLQw3pU5fGvlwOANB0Xgsof/7zn5Wenq5Vq1YpMTFRS5cuVXJysgoKChQREeGtsrzi55c9DP3OvKG0pn1Bl1Na0OVc35pgUvOH3opBRToXOH4+QnL+aElNIDl/xOXn/Xy0wiNgGPqdDgf0kCS9cqL4X0HtMUkfSzr3ZtxXJu+SdO53NyUqwgxL0v/nsR9vB4vmugxUn+3U51jrs15zXariSaym43eIy4HXAsp///d/a9q0afrtb38rSVq1apU2btyoV155RY8//ri3ymp1P79k89T3j5lBpK5LJee3e+upnZZwfog5N9/pX7+Xmkeba0Za6ghmmWN+9jTT/wu65mv9o/r/67tDL5lPGEmq91NGrRlsGhMQrBa8pPb7h5N7jYCW5WMYhtHaO62oqFBISIjefPNNpaSkmO2TJk1SSUmJ3nnnHY/+5eXlKi8vN+dLS0sVGxuro0ePymazNXt9N7/2G8VVPtTs2z3fYz88JUlaHF7m0X4koLtiKw83+/5CAv085k9f4j0obUVdx1Xb77Gu3+2RgO5a7vpOS8KfqXUfhtLlo/9ulnoba+1vL7z8+du1Oy2/7cbu/1LqU19jj+v89Vry99wY3j72ljqO5tqut/d1qX3XpjXrqU1Lnuefc7vdiomJUUlJiex2+8U7G15w7NgxQ5Lx6aeferTPmjXLuP766y/o//TTTxuSmJiYmJiYmNrBdPTo0UtmhTbxmPGcOXOUnp5uzldXV+vHH39UeHi4fHwu+CRek9Sku5YanUH9cB6sgfNgDZwHa+A8NJ1hGDp58qSio6Mv2dcrAaVLly7y8/NTUVGRR3tRUZEcjgu/tBsUFKSgoCCPttDQ0JYsUTabjf8ALYDzYA2cB2vgPFgD56FpLnlp51+88h6UwMBADR48WDk5OWZbdXW1cnJy5HRyoxkAAJc7r13iSU9P16RJkzRkyBBdf/31Wrp0qcrKysynegAAwOXLawHlnnvu0Xfffae5c+fK5XJp4MCB2rRpkyIjI71VkqRzl5OefvrpCy4poXVxHqyB82ANnAdr4Dy0Lq88ZgwAAHAxfIsHAABYDgEFAABYDgEFAABYDgEFAABYDgHlZ5YvX67u3burQ4cOSkxM1M6drfctkstRRkaGrrvuOnXu3FkRERFKSUlRQUGBR58zZ84oLS1N4eHh6tSpk1JTUy94wR+a16JFi+Tj46NHHnnEbOM8tI5jx47pN7/5jcLDwxUcHKx+/fpp165d5nLDMDR37lxFRUUpODhYSUlJ+vrrr71YcftTVVWlp556SvHx8QoODtZVV12lZ555Rj9/noTz0Eqa4dM67UJWVpYRGBhovPLKK0Z+fr4xbdo0IzQ01CgqKvJ2ae1WcnKysXbtWmP//v3Gnj17jFGjRhmxsbHGqVOnzD4PPPCAERMTY+Tk5Bi7du0ybrjhBuOXv/ylF6tu33bu3Gl0797d6N+/v/Hwww+b7ZyHlvfjjz8acXFxxuTJk40dO3YY//jHP4zNmzcbBw8eNPssWrTIsNvtxoYNG4wvvvjCuP322434+Hjjn//8pxcrb18WLlxohIeHG9nZ2UZhYaHxxhtvGJ06dTJefPFFsw/noXUQUP7l+uuvN9LS0sz5qqoqIzo62sjIyPBiVZeX4uJiQ5KRm5trGIZhlJSUGAEBAcYbb7xh9vnyyy8NSUZeXp63ymy3Tp48aVxzzTXGli1bjH/7t38zAwrnoXXMnj3buOmmm+pcXl1dbTgcDuO5554z20pKSoygoCDjT3/6U2uUeFkYPXq0MWXKFI+2u+66y5gwYYJhGJyH1sQlHkkVFRXavXu3kpKSzDZfX18lJSUpLy/Pi5VdXkpLSyVJYWFhkqTdu3ersrLS47z06tVLsbGxnJcWkJaWptGjR3v8viXOQ2t59913NWTIEI0dO1YREREaNGiQ1qxZYy4vLCyUy+XyOA92u12JiYmch2b0y1/+Ujk5Ofr73/8uSfriiy/0ySefaOTIkZI4D62pTXzNuKV9//33qqqquuAttpGRkfrqq6+8VNXlpbq6Wo888ohuvPFGJSQkSJJcLpcCAwMv+DBkZGSkXC6XF6psv7KysvR///d/+vzzzy9YxnloHf/4xz+0cuVKpaen64knntDnn3+uhx56SIGBgZo0aZL5u67t3ynOQ/N5/PHH5Xa71atXL/n5+amqqkoLFy7UhAkTJInz0IoIKLCEtLQ07d+/X5988om3S7nsHD16VA8//LC2bNmiDh06eLucy1Z1dbWGDBmiZ599VpI0aNAg7d+/X6tWrdKkSZO8XN3l4y9/+Ytef/11rV+/Xn379tWePXv0yCOPKDo6mvPQyrjEI6lLly7y8/O74KmEoqIiORwOL1V1+Zg5c6ays7P117/+Vd26dTPbHQ6HKioqVFJS4tGf89K8du/ereLiYl177bXy9/eXv7+/cnNztWzZMvn7+ysyMpLz0AqioqLUp08fj7bevXvryJEjkmT+rvl3qmXNmjVLjz/+uMaNG6d+/fpp4sSJevTRR5WRkSGJ89CaCCiSAgMDNXjwYOXk5Jht1dXVysnJkdPp9GJl7ZthGJo5c6befvttbdu2TfHx8R7LBw8erICAAI/zUlBQoCNHjnBemtHw4cO1b98+7dmzx5yGDBmiCRMmmD9zHlrejTfeeMFj9n//+98VFxcnSYqPj5fD4fA4D263Wzt27OA8NKPTp0/L19fzT6Ofn5+qq6slcR5albfv0rWKrKwsIygoyMjMzDQOHDhgTJ8+3QgNDTVcLpe3S2u3ZsyYYdjtdmP79u3GiRMnzOn06dNmnwceeMCIjY01tm3bZuzatctwOp2G0+n0YtWXh58/xWMYnIfWsHPnTsPf399YuHCh8fXXXxuvv/66ERISYrz22mtmn0WLFhmhoaHGO++8Y+zdu9e44447eLy1mU2aNMm48sorzceM33rrLaNLly7GY489ZvbhPLQOAsrPvPTSS0ZsbKwRGBhoXH/99cZnn33m7ZLaNUm1TmvXrjX7/POf/zR+97vfGVdccYUREhJi3HnnncaJEye8V/Rl4vyAwnloHe+9956RkJBgBAUFGb169TJWr17tsby6utp46qmnjMjISCMoKMgYPny4UVBQ4KVq2ye32208/PDDRmxsrNGhQwejR48exn/8x38Y5eXlZh/OQ+vwMYyfvR4PAADAArgHBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWA4BBQAAWM7/D3/8BFxk6TuDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(y_true, bins=100, alpha=0.75)\n",
    "ax.hist(y_hat, bins=100, alpha=0.75)\n",
    "ax.hist(y_hat_rf, bins=100, alpha=0.75)\n",
    "ax.legend(['y_true', 'y_hat', 'y_hat_rf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 7/7 [00:00<00:00, 41.76it/s] \n",
      "****Safety check****\n",
      "ne_gcn-4239-07271142.ckpt\n",
      "-----------MSE----------\n",
      "Testing error: 224.50775812064964\n",
      "-----------RMSE----------\n",
      "Testing error: 14.983582953374324\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 11.094060415458236\n",
      "*****************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_659032/205311161.py:24: RuntimeWarning: divide by zero encountered in divide\n",
      "  test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n"
     ]
    }
   ],
   "source": [
    "output = trainer.predict(model, dataloaders=data_module_rf.test_dataloader())\n",
    "y_hat = np.concatenate([out[0] for out in output])\n",
    "y_true = np.concatenate([out[1] for out in output])\n",
    "\n",
    "#df = pd.DataFrame({'y_true': y_true, 'y_hat': y_hat})\n",
    "#df.to_csv(f'{model_name}_pred.csv', index=False)\n",
    "\n",
    "print('****Safety check****')\n",
    "print(f'{model_names[best_model_idx]}')\n",
    "simple_model_evaluation(y_true, y_hat)\n",
    "print('*****************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.496338 ,  9.775331 ,  6.7919927,  0.       ,  0.       ,\n",
       "        8.985818 ,  0.       , 12.014425 ,  9.789407 ,  0.       ,\n",
       "        0.       ,  0.       ,  9.181258 ,  0.       , 12.08317  ,\n",
       "       11.07411  ,  7.8603716,  0.       , 12.8585   , 10.1027155,\n",
       "        0.       , 12.479847 ,  0.       ,  0.       , 16.273756 ,\n",
       "        0.       ,  0.       ,  0.       , 14.144027 , 12.5398245,\n",
       "        7.820635 , 13.721009 ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       , 10.60962  ,  8.107154 , 13.832729 ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       , 10.074494 ,  0.       ,\n",
       "       13.289522 ,  0.       ,  0.       , 18.39261  , 14.327365 ,\n",
       "       10.124605 ,  8.467695 , 13.070946 , 12.289224 ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  9.91142  ,\n",
       "       15.011268 ,  0.       ,  9.646951 , 19.883518 ,  0.       ,\n",
       "       10.729084 ,  0.       , 14.118629 ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       , 13.368807 ,\n",
       "       12.857624 ,  9.751285 ,  0.       , 14.587461 ,  0.       ,\n",
       "        0.       , 13.43855  , 13.148234 , 10.273304 , 21.983803 ,\n",
       "       14.561624 ,  0.       ,  0.       , 13.768454 , 13.980866 ,\n",
       "       10.19212  ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "       15.074907 ,  0.       ,  0.       , 21.873146 , 14.553968 ,\n",
       "       11.963512 ,  0.       , 15.788439 ,  0.       ,  0.       ,\n",
       "       22.578941 ,  0.       ,  0.       ,  0.       , 15.316955 ,\n",
       "        0.       ,  0.       , 22.740503 , 15.140964 ,  0.       ,\n",
       "        0.       , 15.14608  , 14.693883 , 11.335279 , 25.190931 ,\n",
       "        0.       , 11.387909 , 10.070709 , 14.791215 , 15.051511 ,\n",
       "       13.424578 , 24.932428 ,  0.       , 11.591116 ,  0.       ,\n",
       "       14.932372 , 15.7125   , 14.150353 , 24.195509 ,  0.       ,\n",
       "       11.298741 ,  0.       , 15.655726 ,  0.       , 12.490285 ,\n",
       "       23.5988   , 14.647341 ,  0.       ,  0.       , 15.2275305,\n",
       "        0.       ,  0.       , 15.080224 , 15.21636  , 24.399607 ,\n",
       "        0.       ,  0.       ,  0.       , 14.467094 ,  0.       ,\n",
       "       12.456285 , 23.63726  ,  0.       ,  0.       ,  0.       ,\n",
       "       14.167888 , 15.123417 , 12.968453 , 23.746347 ,  0.       ,\n",
       "        0.       ,  0.       , 14.315313 ,  0.       , 12.3781   ,\n",
       "        0.       ,  0.       , 13.181334 ,  0.       ,  7.227364 ,\n",
       "       18.586298 ,  0.       , 10.427716 ,  0.       , 11.919801 ,\n",
       "        0.       ,  7.144992 ,  0.       , 10.010703 ,  0.       ,\n",
       "        8.836375 ,  0.       , 10.933163 , 17.920193 , 13.087697 ,\n",
       "       12.344985 , 10.56182  , 12.437681 , 14.656242 ,  0.       ,\n",
       "       10.77421  ,  0.       , 10.045557 ,  0.       , 17.873335 ,\n",
       "        0.       ,  0.       ,  0.       , 14.382106 , 12.75318  ,\n",
       "       11.958098 ,  0.       , 12.331131 , 10.515165 , 21.293936 ,\n",
       "        0.       , 14.815741 , 13.815293 ,  0.       ,  7.4079175,\n",
       "       11.119751 ,  0.       ,  0.       , 11.141814 ,  6.3148894,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "       11.653353 ,  6.435144 , 12.28112  ,  0.       ,  7.6886096,\n",
       "       17.167162 , 15.960247 , 12.810886 , 12.025651 , 12.577645 ,\n",
       "        0.       , 11.092279 , 12.4619665, 21.054754 ,  0.       ,\n",
       "        7.8610005, 14.575219 , 14.303919 , 11.859796 ,  0.       ,\n",
       "       16.665312 ,  0.       , 13.028758 , 11.39835  , 19.472725 ,\n",
       "       15.19202  , 11.881013 , 16.327984 , 13.344555 , 11.900035 ,\n",
       "       19.585321 , 14.573832 , 14.062983 , 12.515792 ,  0.       ,\n",
       "        0.       , 11.8765135, 17.731073 , 17.216236 , 12.481073 ,\n",
       "       13.525725 ,  0.       , 11.521168 ,  0.       , 19.966305 ,\n",
       "        0.       ,  0.       , 16.36741  ,  9.602934 , 14.141734 ,\n",
       "       12.073411 , 21.62569  ,  0.       ,  0.       ,  0.       ,\n",
       "       12.720655 ,  0.       ,  9.650449 , 18.007746 , 12.359452 ,\n",
       "        0.       ,  0.       , 12.758536 , 10.271186 , 10.337527 ,\n",
       "        0.       , 12.313147 , 12.620329 , 13.053483 , 12.424771 ,\n",
       "        9.64273  ,  0.       , 14.199124 , 15.881115 , 18.597565 ,\n",
       "       18.495094 , 15.255194 , 13.184636 , 21.33191  , 15.7203455,\n",
       "       15.331468 , 12.912292 , 18.608063 , 15.306024 , 13.408194 ,\n",
       "        0.       , 13.6497965,  0.       , 14.140359 ,  0.       ,\n",
       "       10.058866 , 18.42914  ,  0.       ,  0.       ,  0.       ,\n",
       "       14.578964 ,  9.986587 ,  0.       , 13.660974 ,  0.       ,\n",
       "        0.       ,  0.       , 12.604922 ,  0.       , 19.052017 ,\n",
       "        0.       ,  0.       ,  0.       , 17.297283 ,  0.       ,\n",
       "       10.7904215,  0.       ,  0.       , 13.238219 ,  0.       ,\n",
       "       17.305548 ,  0.       , 10.362721 , 19.018587 ,  0.       ,\n",
       "       13.326604 ,  0.       ,  0.       , 12.670038 ,  0.       ,\n",
       "       21.088287 , 14.094192 , 18.819609 ,  0.       , 14.835119 ,\n",
       "        0.       , 12.934245 , 19.12468  ,  0.       , 18.266657 ,\n",
       "       24.663456 , 17.610672 , 14.937148 ,  0.       ,  0.       ,\n",
       "       15.688037 , 15.508531 ,  0.       , 16.064178 , 10.835944 ,\n",
       "       19.713087 , 22.175041 ,  0.       ,  0.       , 15.928795 ,\n",
       "       14.5411005, 12.697763 , 15.844975 ,  0.       ,  0.       ,\n",
       "        0.       , 10.846297 ,  0.       , 18.844738 ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       , 15.926862 ,\n",
       "       13.288731 ,  0.       , 21.293135 , 14.495989 ,  0.       ,\n",
       "        0.       , 16.231218 , 13.514372 , 19.0648   , 12.469024 ,\n",
       "       15.622752 ,  0.       , 17.151485 ,  0.       , 25.243853 ,\n",
       "       16.665342 , 14.485906 , 14.269889 , 19.200392 , 15.429494 ,\n",
       "       14.648344 , 25.478634 , 20.093077 , 17.108912 ,  0.       ,\n",
       "       14.164026 , 16.856873 , 14.605815 , 25.839579 , 20.506723 ,\n",
       "       18.345001 ,  0.       ,  0.       ,  0.       , 16.260862 ,\n",
       "       23.898623 ,  0.       ,  0.       , 17.343279 , 15.003149 ,\n",
       "       12.659091 , 23.118603 , 15.1354685,  0.       , 15.529564 ,\n",
       "        0.       ,  8.362348 , 21.879045 , 14.961221 , 10.146809 ,\n",
       "        0.       , 16.56655  ,  0.       ,  8.679142 , 18.985891 ,\n",
       "       14.147275 ,  0.       ,  0.       , 13.021284 , 10.625659 ,\n",
       "        9.542362 , 18.630814 ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       , 10.031139 , 17.415987 ,  0.       ,\n",
       "        0.       ,  0.       , 13.387229 , 16.590294 ,  0.       ,\n",
       "       10.569836 ,  0.       , 13.91063  ,  0.       ,  0.       ,\n",
       "       13.852479 , 11.688411 ,  9.674841 , 18.179962 , 14.736848 ,\n",
       "        0.       ,  0.       , 13.235546 ,  0.       ,  0.       ,\n",
       "       15.789538 ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "       10.511085 , 21.058733 , 17.746328 , 13.315839 ,  0.       ,\n",
       "       10.41194  ,  0.       ,  8.333136 , 12.373475 , 14.737339 ,\n",
       "       13.605067 ,  0.       , 10.86956  , 12.152347 , 20.788956 ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       , 13.206209 ,\n",
       "       10.4341345, 20.257273 , 13.79539  ,  0.       ,  0.       ,\n",
       "       12.995532 , 13.4334545,  0.       , 19.561    ,  0.       ,\n",
       "        0.       ,  0.       , 13.559156 ,  0.       ,  0.       ,\n",
       "       23.133835 ,  0.       , 10.649685 ,  0.       ,  0.       ,\n",
       "       13.3147335, 11.683612 , 23.610777 ,  0.       ,  0.       ,\n",
       "        0.       , 12.613458 , 13.729819 , 12.022133 ,  0.       ,\n",
       "       14.583062 , 12.827402 ,  0.       , 13.180959 , 14.030555 ,\n",
       "       11.495294 , 23.70316  , 12.238699 , 13.295045 ,  0.       ,\n",
       "       12.123655 ,  8.19829  ,  0.       , 17.428047 ,  0.       ,\n",
       "        0.       ,  0.       , 12.429517 ,  0.       ,  0.       ,\n",
       "       16.873686 ,  0.       , 12.487101 ,  0.       ,  0.       ,\n",
       "        8.486409 ,  0.       , 19.282959 ,  0.       , 11.77157  ,\n",
       "        0.       , 12.234183 ,  0.       ,  8.319516 , 22.478254 ,\n",
       "       12.046171 , 13.197214 ,  0.       , 12.813768 ,  0.       ,\n",
       "        8.779937 , 17.192848 ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  9.330263 ,  0.       , 13.426226 ,\n",
       "        0.       ,  0.       , 12.738047 ,  9.76354  , 10.379182 ,\n",
       "       20.71128  ,  0.       ,  0.       ,  0.       , 13.671207 ,\n",
       "       10.853696 ,  0.       , 22.898392 ,  0.       ,  0.       ,\n",
       "        0.       , 13.176755 , 10.173934 ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       , 13.10582  ,  0.       ,  0.       ,\n",
       "       12.832684 ,  0.       ,  0.       , 14.46012  , 11.08559  ,\n",
       "       10.229672 , 18.72213  , 13.549895 , 13.307505 ,  0.       ,\n",
       "       15.089372 ,  0.       , 12.306904 ,  0.       ,  0.       ,\n",
       "        0.       , 19.528378 , 12.105977 , 14.805645 ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       , 15.373731 , 14.296477 ,\n",
       "       11.150975 ,  0.       , 12.961723 , 14.054593 , 10.078423 ,\n",
       "       15.078874 , 11.342707 ,  0.       , 18.13477  ,  0.       ,\n",
       "       13.049469 ,  0.       , 15.619556 ,  0.       ,  0.       ,\n",
       "        0.       , 13.25715  , 13.471221 ,  0.       , 15.557111 ,\n",
       "       11.499245 ,  0.       , 18.15468  ,  0.       ,  0.       ,\n",
       "       10.136751 , 14.758026 ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       ,  0.       ,  0.       , 15.466508 , 11.510699 ,\n",
       "        0.       , 18.016895 , 14.431128 , 14.062731 ,  0.       ,\n",
       "       15.761476 , 12.245328 , 10.264649 ,  0.       , 14.35027  ,\n",
       "        0.       ,  0.       , 16.596857 ,  0.       , 11.364045 ,\n",
       "       11.415716 ,  0.       , 11.362999 ,  0.       ,  5.8829865,\n",
       "        0.       ,  0.       ,  0.       ,  0.       , 11.721126 ,\n",
       "        8.656602 ,  6.3307347,  0.       , 10.780799 ,  0.       ,\n",
       "        0.       , 12.114851 ,  0.       ,  7.451506 ,  0.       ,\n",
       "       10.8362255,  0.       ,  0.       , 11.887864 ,  8.599506 ,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  6.5222774,\n",
       "       12.737755 ,  0.       ,  6.9088707,  0.       ,  0.       ,\n",
       "        0.       ,  0.       , 12.881962 ,  9.694272 ,  7.5360823,\n",
       "        0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "        0.       , 14.655859 ,  0.       ,  0.       , 14.843239 ,\n",
       "        0.       ,  0.       , 14.799524 , 24.716122 , 16.89758  ,\n",
       "        0.       ,  0.       , 21.784218 , 17.553303 , 15.800254 ,\n",
       "       14.618897 , 24.13729  , 20.070414 , 17.288982 , 16.02138  ,\n",
       "       22.781462 ,  0.       ,  0.       , 27.494808 , 19.82984  ,\n",
       "       16.194332 , 15.86464  ,  0.       , 17.08112  ,  0.       ,\n",
       "       25.388628 , 19.018023 , 16.350067 , 16.079597 ,  0.       ,\n",
       "        0.       ,  0.       , 24.101114 ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "show_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
