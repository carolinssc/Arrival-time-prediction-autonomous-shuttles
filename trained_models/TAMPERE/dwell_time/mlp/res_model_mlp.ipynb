{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../../src')\n",
    "import os\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from data.datamodule import SHOWDataModule\n",
    "from models.gcn_model import NodeEncodedGCN, NodeEncodedGCN_tt, NodeEncodedGCN_1l, NodeEncodedGCN_2l, NodeEncodedGCN_3l\n",
    "\n",
    "\n",
    "def simple_model_evaluation(y_test, y_pred_test):\n",
    "    # Simple model evaluation that computes and prints MSE, RMSE and MAPE for the training and testing set\n",
    "\n",
    "    # train_error_mse = np.square(y_train - y_pred_train).sum() / y_train.shape[0]\n",
    "    test_error_mse = np.square(y_test - y_pred_test).sum() / y_test.shape[0]\n",
    "\n",
    "    # train_error_mape = (100 / y_train.shape[0]) * (\n",
    "    #    np.absolute(y_train - y_pred_train) / y_train\n",
    "    # ).sum()  # y_train should never be 0 since the travel time in a segment cannot be 0\n",
    "    test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
    "\n",
    "    test_error_mae = (1 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test)).sum()\n",
    "    print(\"-----------MSE----------\")\n",
    "    # print(\"Training error: {}\".format(train_error_mse))\n",
    "    print(\"Testing error: {}\".format(test_error_mse))\n",
    "    print(\"-----------RMSE----------\")\n",
    "    # print(\"Training error: {}\".format(np.sqrt(train_error_mse)))\n",
    "    print(\"Testing error: {}\".format(np.sqrt(test_error_mse)))\n",
    "    print(\"-----------MAPE----------\")\n",
    "    # print(\"Training error: {:.2f} %\".format(train_error_mape))\n",
    "    print(\"Testing error: {:.2f} %\".format(test_error_mape))\n",
    "    print(\"-----------MAE----------\")\n",
    "    print(\"Testing error: {}\".format(test_error_mae))\n",
    "    return test_error_mse, np.sqrt(test_error_mse), test_error_mape, test_error_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the checkpoint directory\n",
    "checkpoint_dir = '.'\n",
    "model_names = os.listdir(checkpoint_dir)\n",
    "\n",
    "# remove all files not ending on ckpt\n",
    "model_names = [model_name for model_name in model_names if model_name.endswith('ckpt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ne_gcn-6094-07271131.ckpt',\n",
       " 'ne_gcn-6125-07271131.ckpt',\n",
       " 'ne_gcn-6831-07271131.ckpt',\n",
       " 'ne_gcn-5545-07271131.ckpt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the datamodule\n",
    "site_name = 'TAMPERE_FINAL'\n",
    "transform = 'maxmin'\n",
    "batch_size = 64\n",
    "empty_graph = True\n",
    "time_kind = 'dwell_times'\n",
    "data_module = SHOWDataModule(\n",
    "    site_name=site_name,\n",
    "    transform=transform,\n",
    "    num_lags=2,\n",
    "    train_frac=0.9,\n",
    "    batch_size=batch_size,\n",
    "    empty_graph=empty_graph,\n",
    "    verbose=False,\n",
    "    time_kind=time_kind,\n",
    ")\n",
    "transform = data_module.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-6094-07271131.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/manity/SHOW_folder/SHOW_ML_Service/notebooks/trained_models2/TAMPERE/dwell_time/mlp/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 18.17it/s]-----------MSE----------\n",
      "Testing error: 189.862548828125\n",
      "-----------RMSE----------\n",
      "Testing error: 13.779062271118164\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 8.145425796508789\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 17.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ne_gcn-6125-07271131.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 115.36it/s]-----------MSE----------\n",
      "Testing error: 186.3000946044922\n",
      "-----------RMSE----------\n",
      "Testing error: 13.649179458618164\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 8.240818977355957\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 104.36it/s]\n",
      "ne_gcn-6831-07271131.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 109.20it/s]-----------MSE----------\n",
      "Testing error: 190.6352081298828\n",
      "-----------RMSE----------\n",
      "Testing error: 13.8070707321167\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 8.22043228149414\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 102.99it/s]\n",
      "ne_gcn-5545-07271131.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 118.49it/s]-----------MSE----------\n",
      "Testing error: 186.85252380371094\n",
      "-----------RMSE----------\n",
      "Testing error: 13.669401168823242\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 8.203258514404297\n",
      "Testing DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 109.36it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the models and evaluate them\n",
    "results = []\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "\n",
    "    # Load model checkpoint\n",
    "    checkpoint_dict = torch.load(model_name)\n",
    "    model = NodeEncodedGCN_1l(\n",
    "        transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "        weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "        lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "        drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "        batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "        input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "        hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "        aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    "    )\n",
    "    model = model.load_from_checkpoint(f'{model_name}')\n",
    "\n",
    "    trainer = pl.Trainer(gpus=1)\n",
    "    results.append(trainer.test(model, datamodule=data_module, verbose=False))\n",
    "\n",
    "# Print the results\n",
    "mse_arr = np.array([run_dict[0]['test/error_mse'] for run_dict in results])\n",
    "mae_arr = np.array([run_dict[0]['test/error_mae'] for run_dict in results])\n",
    "mape_arr = np.array([run_dict[0]['test/error_mape'] for run_dict in results])\n",
    "rmse_arr = np.array([run_dict[0]['test/error_rmse'] for run_dict in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for TAMPERE_FINAL with <class 'data.datamodule.MaxMin'> transform and dwell_times time kind\n",
      "MSE: 188.41259384155273 +/- 1.8667388199295514\n",
      "MAE: 8.202483892440796 +/- 0.03552446254215281\n",
      "RMSE: 13.726178407669067 +/- 0.06799405152979032\n"
     ]
    }
   ],
   "source": [
    "print(f'Results for {site_name} with {type(transform)} transform and {time_kind} time kind')\n",
    "print(f'MSE: {mse_arr.mean()} +/- {mse_arr.std()}')\n",
    "print(f'MAE: {mae_arr.mean()} +/- {mae_arr.std()}')\n",
    "print(f'RMSE: {rmse_arr.mean()} +/- {rmse_arr.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-6125-07271131.ckpt\n",
      "Predicting: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 63.48it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f128cf61340>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = model_names[np.argmin(mse_arr)]\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint_dict = torch.load(best_model)\n",
    "model = NodeEncodedGCN_1l(\n",
    "    transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "    weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "    lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "    drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "    batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "    input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "    hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "    aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    ")\n",
    "model = model.load_from_checkpoint(f'{best_model}')\n",
    "\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "output = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
    "y_hat = np.concatenate([out[0] for out in output])\n",
    "y_true = np.concatenate([out[1] for out in output])\n",
    "\n",
    "df = pd.DataFrame({'y_true': y_true, 'y_hat': y_hat})\n",
    "df.to_csv(f'{best_model}_pred.csv', index=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(y_true, bins=100, alpha=0.75)\n",
    "ax.hist(y_hat, bins=100, alpha=0.75)\n",
    "ax.legend(['y_true', 'y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "show_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
