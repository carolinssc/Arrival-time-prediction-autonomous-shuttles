{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../../src')\n",
    "import os\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from data.datamodule import SHOWDataModule\n",
    "from models.gcn_model import NodeEncodedGCN, NodeEncodedGCN_tt, NodeEncodedGCN_1l, NodeEncodedGCN_2l, NodeEncodedGCN_3l\n",
    "\n",
    "\n",
    "def simple_model_evaluation(y_test, y_pred_test):\n",
    "    # Simple model evaluation that computes and prints MSE, RMSE and MAPE for the training and testing set\n",
    "\n",
    "    # train_error_mse = np.square(y_train - y_pred_train).sum() / y_train.shape[0]\n",
    "    test_error_mse = np.square(y_test - y_pred_test).sum() / y_test.shape[0]\n",
    "\n",
    "    # train_error_mape = (100 / y_train.shape[0]) * (\n",
    "    #    np.absolute(y_train - y_pred_train) / y_train\n",
    "    # ).sum()  # y_train should never be 0 since the travel time in a segment cannot be 0\n",
    "    test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
    "\n",
    "    test_error_mae = (1 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test)).sum()\n",
    "    print(\"-----------MSE----------\")\n",
    "    # print(\"Training error: {}\".format(train_error_mse))\n",
    "    print(\"Testing error: {}\".format(test_error_mse))\n",
    "    print(\"-----------RMSE----------\")\n",
    "    # print(\"Training error: {}\".format(np.sqrt(train_error_mse)))\n",
    "    print(\"Testing error: {}\".format(np.sqrt(test_error_mse)))\n",
    "    print(\"-----------MAPE----------\")\n",
    "    # print(\"Training error: {:.2f} %\".format(train_error_mape))\n",
    "    print(\"Testing error: {:.2f} %\".format(test_error_mape))\n",
    "    print(\"-----------MAE----------\")\n",
    "    print(\"Testing error: {}\".format(test_error_mae))\n",
    "    return test_error_mse, np.sqrt(test_error_mse), test_error_mape, test_error_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the checkpoint directory\n",
    "checkpoint_dir = '.'\n",
    "model_names = os.listdir(checkpoint_dir)\n",
    "\n",
    "# remove all files not ending on ckpt\n",
    "model_names = [model_name for model_name in model_names if model_name.endswith('ckpt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ne_gcn-4355-07271404.ckpt',\n",
       " 'ne_gcn-7872-07271404.ckpt',\n",
       " 'ne_gcn-5754-07271404.ckpt',\n",
       " 'ne_gcn-7104-07271404.ckpt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the datamodule\n",
    "site_name = 'MADRID'\n",
    "transform = 'maxmin'\n",
    "batch_size = 64\n",
    "empty_graph = False\n",
    "time_kind = 'travel_times'\n",
    "data_module = SHOWDataModule(\n",
    "    site_name=site_name,\n",
    "    transform=transform,\n",
    "    num_lags=2,\n",
    "    train_frac=0.9,\n",
    "    batch_size=batch_size,\n",
    "    empty_graph=empty_graph,\n",
    "    verbose=False,\n",
    "    time_kind=time_kind,\n",
    ")\n",
    "transform = data_module.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-4355-07271404.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/manity/SHOW_folder/SHOW_ML_Service/notebooks/trained_models2/MADRID/travel_time/gcn/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 15.87it/s]-----------MSE----------\n",
      "Testing error: 512.8764038085938\n",
      "-----------RMSE----------\n",
      "Testing error: 22.646774291992188\n",
      "-----------MAPE----------\n",
      "Testing error: 36.77 %\n",
      "-----------MAE----------\n",
      "Testing error: 16.38115119934082\n",
      "Testing DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 15.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ne_gcn-7872-07271404.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 116.85it/s]-----------MSE----------\n",
      "Testing error: 521.591796875\n",
      "-----------RMSE----------\n",
      "Testing error: 22.8383846282959\n",
      "-----------MAPE----------\n",
      "Testing error: 36.95 %\n",
      "-----------MAE----------\n",
      "Testing error: 16.642202377319336\n",
      "Testing DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 105.20it/s]\n",
      "ne_gcn-5754-07271404.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 117.48it/s]-----------MSE----------\n",
      "Testing error: 515.7188110351562\n",
      "-----------RMSE----------\n",
      "Testing error: 22.709444046020508\n",
      "-----------MAPE----------\n",
      "Testing error: 36.83 %\n",
      "-----------MAE----------\n",
      "Testing error: 16.366125106811523\n",
      "Testing DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 106.10it/s]\n",
      "ne_gcn-7104-07271404.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 117.52it/s]-----------MSE----------\n",
      "Testing error: 517.1296997070312\n",
      "-----------RMSE----------\n",
      "Testing error: 22.74048614501953\n",
      "-----------MAPE----------\n",
      "Testing error: 37.59 %\n",
      "-----------MAE----------\n",
      "Testing error: 16.487070083618164\n",
      "Testing DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 106.43it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the models and evaluate them\n",
    "results = []\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "\n",
    "    # Load model checkpoint\n",
    "    checkpoint_dict = torch.load(model_name)\n",
    "    model = NodeEncodedGCN_1l(\n",
    "        transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "        weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "        lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "        drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "        batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "        input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "        hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "        aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    "    )\n",
    "    model = model.load_from_checkpoint(f'{model_name}')\n",
    "\n",
    "    trainer = pl.Trainer(gpus=1)\n",
    "    results.append(trainer.test(model, datamodule=data_module, verbose=False))\n",
    "\n",
    "# Print the results\n",
    "mse_arr = np.array([run_dict[0]['test/error_mse'] for run_dict in results])\n",
    "mae_arr = np.array([run_dict[0]['test/error_mae'] for run_dict in results])\n",
    "mape_arr = np.array([run_dict[0]['test/error_mape'] for run_dict in results])\n",
    "rmse_arr = np.array([run_dict[0]['test/error_rmse'] for run_dict in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for MADRID with <class 'data.datamodule.MaxMin'> transform and travel_times time kind\n",
      "MSE: 516.8291778564453 +/- 3.1476257103476746\n",
      "MAE: 16.46913719177246 +/- 0.11025671359434772\n",
      "RMSE: 22.73377227783203 +/- 0.0691905562296099\n"
     ]
    }
   ],
   "source": [
    "print(f'Results for {site_name} with {type(transform)} transform and {time_kind} time kind')\n",
    "print(f'MSE: {mse_arr.mean()} +/- {mse_arr.std()}')\n",
    "print(f'MAE: {mae_arr.mean()} +/- {mae_arr.std()}')\n",
    "print(f'RMSE: {rmse_arr.mean()} +/- {rmse_arr.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-4355-07271404.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 55.47it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4190322df0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = model_names[np.argmin(mse_arr)]\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint_dict = torch.load(best_model)\n",
    "model = NodeEncodedGCN_1l(\n",
    "    transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "    weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "    lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "    drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "    batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "    input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "    hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "    aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    ")\n",
    "model = model.load_from_checkpoint(f'{best_model}')\n",
    "\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "output = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
    "y_hat = np.concatenate([out[0] for out in output])\n",
    "y_true = np.concatenate([out[1] for out in output])\n",
    "\n",
    "df = pd.DataFrame({'y_true': y_true, 'y_hat': y_hat})\n",
    "df.to_csv(f'{best_model}_pred.csv', index=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(y_true, bins=100, alpha=0.75)\n",
    "ax.hist(y_hat, bins=100, alpha=0.75)\n",
    "ax.legend(['y_true', 'y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "show_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
