{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../../src')\n",
    "import os\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from data.datamodule import SHOWDataModule\n",
    "from models.gcn_model import NodeEncodedGCN, NodeEncodedGCN_tt, NodeEncodedGCN_1l, NodeEncodedGCN_2l, NodeEncodedGCN_3l\n",
    "\n",
    "\n",
    "def simple_model_evaluation(y_test, y_pred_test):\n",
    "    # Simple model evaluation that computes and prints MSE, RMSE and MAPE for the training and testing set\n",
    "\n",
    "    # train_error_mse = np.square(y_train - y_pred_train).sum() / y_train.shape[0]\n",
    "    test_error_mse = np.square(y_test - y_pred_test).sum() / y_test.shape[0]\n",
    "\n",
    "    # train_error_mape = (100 / y_train.shape[0]) * (\n",
    "    #    np.absolute(y_train - y_pred_train) / y_train\n",
    "    # ).sum()  # y_train should never be 0 since the travel time in a segment cannot be 0\n",
    "    test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
    "\n",
    "    test_error_mae = (1 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test)).sum()\n",
    "    print(\"-----------MSE----------\")\n",
    "    # print(\"Training error: {}\".format(train_error_mse))\n",
    "    print(\"Testing error: {}\".format(test_error_mse))\n",
    "    print(\"-----------RMSE----------\")\n",
    "    # print(\"Training error: {}\".format(np.sqrt(train_error_mse)))\n",
    "    print(\"Testing error: {}\".format(np.sqrt(test_error_mse)))\n",
    "    print(\"-----------MAPE----------\")\n",
    "    # print(\"Training error: {:.2f} %\".format(train_error_mape))\n",
    "    print(\"Testing error: {:.2f} %\".format(test_error_mape))\n",
    "    print(\"-----------MAE----------\")\n",
    "    print(\"Testing error: {}\".format(test_error_mae))\n",
    "    return test_error_mse, np.sqrt(test_error_mse), test_error_mape, test_error_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the checkpoint directory\n",
    "checkpoint_dir = '.'\n",
    "model_names = os.listdir(checkpoint_dir)\n",
    "\n",
    "# remove all files not ending on ckpt\n",
    "model_names = [model_name for model_name in model_names if model_name.endswith('ckpt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ne_gcn-387-07271343.ckpt',\n",
       " 'ne_gcn-5809-07271343.ckpt',\n",
       " 'ne_gcn-6134-07271343.ckpt',\n",
       " 'ne_gcn-4726-07271343.ckpt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the datamodule\n",
    "site_name = 'MADRID'\n",
    "transform = 'maxmin'\n",
    "batch_size = 64\n",
    "empty_graph = False\n",
    "time_kind = 'dwell_times'\n",
    "data_module = SHOWDataModule(\n",
    "    site_name=site_name,\n",
    "    transform=transform,\n",
    "    num_lags=2,\n",
    "    train_frac=0.9,\n",
    "    batch_size=batch_size,\n",
    "    empty_graph=empty_graph,\n",
    "    verbose=False,\n",
    "    time_kind=time_kind,\n",
    ")\n",
    "transform = data_module.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-387-07271343.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 18.08it/s]-----------MSE----------\n",
      "Testing error: 292.338623046875\n",
      "-----------RMSE----------\n",
      "Testing error: 17.09791374206543\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 4.217339038848877\n",
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 17.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ne_gcn-5809-07271343.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 114.58it/s]-----------MSE----------\n",
      "Testing error: 290.9841613769531\n",
      "-----------RMSE----------\n",
      "Testing error: 17.058258056640625\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 4.203815937042236\n",
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 105.28it/s]\n",
      "ne_gcn-6134-07271343.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 117.77it/s]-----------MSE----------\n",
      "Testing error: 290.6111755371094\n",
      "-----------RMSE----------\n",
      "Testing error: 17.047321319580078\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 4.207107067108154\n",
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 107.95it/s]\n",
      "ne_gcn-4726-07271343.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 116.04it/s]-----------MSE----------\n",
      "Testing error: 290.52862548828125\n",
      "-----------RMSE----------\n",
      "Testing error: 17.04490089416504\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 4.231344699859619\n",
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 107.24it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the models and evaluate them\n",
    "results = []\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "\n",
    "    # Load model checkpoint\n",
    "    checkpoint_dict = torch.load(model_name)\n",
    "    model = NodeEncodedGCN_1l(\n",
    "        transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "        weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "        lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "        drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "        batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "        input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "        hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "        aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    "    )\n",
    "    model = model.load_from_checkpoint(f'{model_name}')\n",
    "\n",
    "    trainer = pl.Trainer(gpus=1)\n",
    "    results.append(trainer.test(model, datamodule=data_module, verbose=False))\n",
    "\n",
    "# Print the results\n",
    "mse_arr = np.array([run_dict[0]['test/error_mse'] for run_dict in results])\n",
    "mae_arr = np.array([run_dict[0]['test/error_mae'] for run_dict in results])\n",
    "mape_arr = np.array([run_dict[0]['test/error_mape'] for run_dict in results])\n",
    "rmse_arr = np.array([run_dict[0]['test/error_rmse'] for run_dict in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for MADRID with <class 'data.datamodule.MaxMin'> transform and dwell_times time kind\n",
      "MSE: 291.1156463623047 +/- 0.7266437559746822\n",
      "MAE: 4.214901685714722 +/- 0.010723377584991957\n",
      "RMSE: 17.062098503112793 +/- 0.021281466567294287\n"
     ]
    }
   ],
   "source": [
    "print(f'Results for {site_name} with {type(transform)} transform and {time_kind} time kind')\n",
    "print(f'MSE: {mse_arr.mean()} +/- {mse_arr.std()}')\n",
    "print(f'MAE: {mae_arr.mean()} +/- {mae_arr.std()}')\n",
    "print(f'RMSE: {rmse_arr.mean()} +/- {rmse_arr.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-4726-07271343.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 60.64it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f05cf9c5fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = model_names[np.argmin(mse_arr)]\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint_dict = torch.load(best_model)\n",
    "model = NodeEncodedGCN_1l(\n",
    "    transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "    weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "    lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "    drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "    batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "    input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "    hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "    aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    ")\n",
    "model = model.load_from_checkpoint(f'{best_model}')\n",
    "\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "output = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
    "y_hat = np.concatenate([out[0] for out in output])\n",
    "y_true = np.concatenate([out[1] for out in output])\n",
    "\n",
    "df = pd.DataFrame({'y_true': y_true, 'y_hat': y_hat})\n",
    "df.to_csv(f'{best_model}_pred.csv', index=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(y_true, bins=100, alpha=0.75)\n",
    "ax.hist(y_hat, bins=100, alpha=0.75)\n",
    "ax.legend(['y_true', 'y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "show_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
