{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../../src')\n",
    "import os\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from data.datamodule import SHOWDataModule\n",
    "from models.gcn_model import NodeEncodedGCN, NodeEncodedGCN_tt, NodeEncodedGCN_1l, NodeEncodedGCN_2l, NodeEncodedGCN_3l\n",
    "\n",
    "\n",
    "def simple_model_evaluation(y_test, y_pred_test):\n",
    "    # Simple model evaluation that computes and prints MSE, RMSE and MAPE for the training and testing set\n",
    "\n",
    "    # train_error_mse = np.square(y_train - y_pred_train).sum() / y_train.shape[0]\n",
    "    test_error_mse = np.square(y_test - y_pred_test).sum() / y_test.shape[0]\n",
    "\n",
    "    # train_error_mape = (100 / y_train.shape[0]) * (\n",
    "    #    np.absolute(y_train - y_pred_train) / y_train\n",
    "    # ).sum()  # y_train should never be 0 since the travel time in a segment cannot be 0\n",
    "    test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
    "\n",
    "    test_error_mae = (1 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test)).sum()\n",
    "    print(\"-----------MSE----------\")\n",
    "    # print(\"Training error: {}\".format(train_error_mse))\n",
    "    print(\"Testing error: {}\".format(test_error_mse))\n",
    "    print(\"-----------RMSE----------\")\n",
    "    # print(\"Training error: {}\".format(np.sqrt(train_error_mse)))\n",
    "    print(\"Testing error: {}\".format(np.sqrt(test_error_mse)))\n",
    "    print(\"-----------MAPE----------\")\n",
    "    # print(\"Training error: {:.2f} %\".format(train_error_mape))\n",
    "    print(\"Testing error: {:.2f} %\".format(test_error_mape))\n",
    "    print(\"-----------MAE----------\")\n",
    "    print(\"Testing error: {}\".format(test_error_mae))\n",
    "    return test_error_mse, np.sqrt(test_error_mse), test_error_mape, test_error_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the checkpoint directory\n",
    "checkpoint_dir = '.'\n",
    "model_names = os.listdir(checkpoint_dir)\n",
    "\n",
    "# remove all files not ending on ckpt\n",
    "model_names = [model_name for model_name in model_names if model_name.endswith('ckpt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ne_gcn-8248-07271341.ckpt',\n",
       " 'ne_gcn-3617-07271341.ckpt',\n",
       " 'ne_gcn-7150-07271341.ckpt',\n",
       " 'ne_gcn-7095-07271341.ckpt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the datamodule\n",
    "site_name = 'MADRID'\n",
    "transform = 'maxmin'\n",
    "batch_size = 64\n",
    "empty_graph = True\n",
    "time_kind = 'dwell_times'\n",
    "data_module = SHOWDataModule(\n",
    "    site_name=site_name,\n",
    "    transform=transform,\n",
    "    num_lags=2,\n",
    "    train_frac=0.9,\n",
    "    batch_size=batch_size,\n",
    "    empty_graph=empty_graph,\n",
    "    verbose=False,\n",
    "    time_kind=time_kind,\n",
    ")\n",
    "transform = data_module.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-8248-07271341.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/manity/SHOW_folder/SHOW_ML_Service/notebooks/trained_models2/MADRID/dwell_time/mlp/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 18.47it/s]-----------MSE----------\n",
      "Testing error: 291.46612548828125\n",
      "-----------RMSE----------\n",
      "Testing error: 17.072378158569336\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 4.203523635864258\n",
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 18.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ne_gcn-3617-07271341.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 184.88it/s]-----------MSE----------\n",
      "Testing error: 277.40069580078125\n",
      "-----------RMSE----------\n",
      "Testing error: 16.655349731445312\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 5.1041646003723145\n",
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 169.40it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-7150-07271341.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 111.67it/s]-----------MSE----------\n",
      "Testing error: 282.8570861816406\n",
      "-----------RMSE----------\n",
      "Testing error: 16.818355560302734\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 4.663820266723633\n",
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 105.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ne_gcn-7095-07271341.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 178.17it/s]-----------MSE----------\n",
      "Testing error: 290.6311340332031\n",
      "-----------RMSE----------\n",
      "Testing error: 17.04790687561035\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 4.19441556930542\n",
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 163.30it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the models and evaluate them\n",
    "results = []\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "\n",
    "    # Load model checkpoint\n",
    "    checkpoint_dict = torch.load(model_name)\n",
    "    model = NodeEncodedGCN_1l(\n",
    "        transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "        weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "        lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "        drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "        batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "        input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "        hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "        aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    "    )\n",
    "    model = model.load_from_checkpoint(f'{model_name}')\n",
    "\n",
    "    trainer = pl.Trainer(gpus=1)\n",
    "    results.append(trainer.test(model, datamodule=data_module, verbose=False))\n",
    "\n",
    "# Print the results\n",
    "mse_arr = np.array([run_dict[0]['test/error_mse'] for run_dict in results])\n",
    "mae_arr = np.array([run_dict[0]['test/error_mae'] for run_dict in results])\n",
    "mape_arr = np.array([run_dict[0]['test/error_mape'] for run_dict in results])\n",
    "rmse_arr = np.array([run_dict[0]['test/error_rmse'] for run_dict in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for MADRID with <class 'data.datamodule.MaxMin'> transform and dwell_times time kind\n",
      "MSE: 285.58876037597656 +/- 5.798176397670175\n",
      "MAE: 4.541481018066406 +/- 0.3762476988192813\n",
      "RMSE: 16.898497581481934 +/- 0.17182928504501102\n"
     ]
    }
   ],
   "source": [
    "print(f'Results for {site_name} with {type(transform)} transform and {time_kind} time kind')\n",
    "print(f'MSE: {mse_arr.mean()} +/- {mse_arr.std()}')\n",
    "print(f'MAE: {mae_arr.mean()} +/- {mae_arr.std()}')\n",
    "print(f'RMSE: {rmse_arr.mean()} +/- {rmse_arr.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-3617-07271341.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 81.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3046242040>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = model_names[np.argmin(mse_arr)]\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint_dict = torch.load(best_model)\n",
    "model = NodeEncodedGCN_1l(\n",
    "    transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "    weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "    lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "    drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "    batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "    input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "    hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "    aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    ")\n",
    "model = model.load_from_checkpoint(f'{best_model}')\n",
    "\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "output = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
    "y_hat = np.concatenate([out[0] for out in output])\n",
    "y_true = np.concatenate([out[1] for out in output])\n",
    "\n",
    "df = pd.DataFrame({'y_true': y_true, 'y_hat': y_hat})\n",
    "df.to_csv(f'{best_model}_pred.csv', index=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(y_true, bins=100, alpha=0.75)\n",
    "ax.hist(y_hat, bins=100, alpha=0.75)\n",
    "ax.legend(['y_true', 'y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "show_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
