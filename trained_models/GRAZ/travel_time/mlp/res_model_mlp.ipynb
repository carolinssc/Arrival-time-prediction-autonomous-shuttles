{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../../src')\n",
    "import os\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from data.datamodule import SHOWDataModule\n",
    "from models.gcn_model import NodeEncodedGCN, NodeEncodedGCN_tt, NodeEncodedGCN_1l, NodeEncodedGCN_2l, NodeEncodedGCN_3l\n",
    "\n",
    "\n",
    "def simple_model_evaluation(y_test, y_pred_test):\n",
    "    # Simple model evaluation that computes and prints MSE, RMSE and MAPE for the training and testing set\n",
    "\n",
    "    # train_error_mse = np.square(y_train - y_pred_train).sum() / y_train.shape[0]\n",
    "    test_error_mse = np.square(y_test - y_pred_test).sum() / y_test.shape[0]\n",
    "\n",
    "    # train_error_mape = (100 / y_train.shape[0]) * (\n",
    "    #    np.absolute(y_train - y_pred_train) / y_train\n",
    "    # ).sum()  # y_train should never be 0 since the travel time in a segment cannot be 0\n",
    "    test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
    "\n",
    "    test_error_mae = (1 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test)).sum()\n",
    "    print(\"-----------MSE----------\")\n",
    "    # print(\"Training error: {}\".format(train_error_mse))\n",
    "    print(\"Testing error: {}\".format(test_error_mse))\n",
    "    print(\"-----------RMSE----------\")\n",
    "    # print(\"Training error: {}\".format(np.sqrt(train_error_mse)))\n",
    "    print(\"Testing error: {}\".format(np.sqrt(test_error_mse)))\n",
    "    print(\"-----------MAPE----------\")\n",
    "    # print(\"Training error: {:.2f} %\".format(train_error_mape))\n",
    "    print(\"Testing error: {:.2f} %\".format(test_error_mape))\n",
    "    print(\"-----------MAE----------\")\n",
    "    print(\"Testing error: {}\".format(test_error_mae))\n",
    "    return test_error_mse, np.sqrt(test_error_mse), test_error_mape, test_error_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the checkpoint directory\n",
    "checkpoint_dir = '.'\n",
    "model_names = os.listdir(checkpoint_dir)\n",
    "\n",
    "# remove all files not ending on ckpt\n",
    "model_names = [model_name for model_name in model_names if model_name.endswith('ckpt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ne_gcn-7096-07271314.ckpt',\n",
       " 'ne_gcn-9670-07271314.ckpt',\n",
       " 'ne_gcn-937-07271314.ckpt',\n",
       " 'ne_gcn-8464-07271314.ckpt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the datamodule\n",
    "site_name = 'GRAZ'\n",
    "transform = 'maxmin'\n",
    "batch_size = 64\n",
    "empty_graph = True\n",
    "time_kind = 'travel_times'\n",
    "data_module = SHOWDataModule(\n",
    "    site_name=site_name,\n",
    "    transform=transform,\n",
    "    num_lags=2,\n",
    "    train_frac=0.9,\n",
    "    batch_size=batch_size,\n",
    "    empty_graph=empty_graph,\n",
    "    verbose=False,\n",
    "    time_kind=time_kind,\n",
    ")\n",
    "transform = data_module.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-7096-07271314.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/manity/SHOW_folder/SHOW_ML_Service/notebooks/trained_models2/GRAZ/travel_time/mlp/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.73it/s]-----------MSE----------\n",
      "Testing error: 301.0350341796875\n",
      "-----------RMSE----------\n",
      "Testing error: 17.350360870361328\n",
      "-----------MAPE----------\n",
      "Testing error: 9.87 %\n",
      "-----------MAE----------\n",
      "Testing error: 13.050298690795898\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-9670-07271314.ckpt\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 194.86it/s]-----------MSE----------\n",
      "Testing error: 313.677001953125\n",
      "-----------RMSE----------\n",
      "Testing error: 17.710927963256836\n",
      "-----------MAPE----------\n",
      "Testing error: 10.02 %\n",
      "-----------MAE----------\n",
      "Testing error: 13.346924781799316\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 137.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-937-07271314.ckpt\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 171.01it/s]-----------MSE----------\n",
      "Testing error: 311.5058288574219\n",
      "-----------RMSE----------\n",
      "Testing error: 17.64952850341797\n",
      "-----------MAPE----------\n",
      "Testing error: 10.22 %\n",
      "-----------MAE----------\n",
      "Testing error: 13.473944664001465\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 123.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-8464-07271314.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 121.82it/s]-----------MSE----------\n",
      "Testing error: 332.3450012207031\n",
      "-----------RMSE----------\n",
      "Testing error: 18.230331420898438\n",
      "-----------MAPE----------\n",
      "Testing error: 10.12 %\n",
      "-----------MAE----------\n",
      "Testing error: 13.64046859741211\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 86.03it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the models and evaluate them\n",
    "results = []\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "\n",
    "    # Load model checkpoint\n",
    "    checkpoint_dict = torch.load(model_name)\n",
    "    model = NodeEncodedGCN_1l(\n",
    "        transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "        weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "        lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "        drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "        batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "        input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "        hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "        aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    "    )\n",
    "    model = model.load_from_checkpoint(f'{model_name}')\n",
    "\n",
    "    trainer = pl.Trainer(gpus=1)\n",
    "    results.append(trainer.test(model, datamodule=data_module, verbose=False))\n",
    "\n",
    "# Print the results\n",
    "mse_arr = np.array([run_dict[0]['test/error_mse'] for run_dict in results])\n",
    "mae_arr = np.array([run_dict[0]['test/error_mae'] for run_dict in results])\n",
    "mape_arr = np.array([run_dict[0]['test/error_mape'] for run_dict in results])\n",
    "rmse_arr = np.array([run_dict[0]['test/error_rmse'] for run_dict in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for GRAZ with <class 'data.datamodule.MaxMin'> transform and travel_times time kind\n",
      "MSE: 314.6407165527344 +/- 11.283977081823076\n",
      "MAE: 13.377909183502197 +/- 0.21589866108176256\n",
      "RMSE: 17.735287189483643 +/- 0.31669582660188245\n"
     ]
    }
   ],
   "source": [
    "print(f'Results for {site_name} with {type(transform)} transform and {time_kind} time kind')\n",
    "print(f'MSE: {mse_arr.mean()} +/- {mse_arr.std()}')\n",
    "print(f'MAE: {mae_arr.mean()} +/- {mae_arr.std()}')\n",
    "print(f'RMSE: {rmse_arr.mean()} +/- {rmse_arr.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-7096-07271314.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 25.05it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2f7f92dc70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = model_names[np.argmin(mse_arr)]\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint_dict = torch.load(best_model)\n",
    "model = NodeEncodedGCN_1l(\n",
    "    transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "    weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "    lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "    drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "    batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "    input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "    hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "    aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    ")\n",
    "model = model.load_from_checkpoint(f'{best_model}')\n",
    "\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "output = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
    "y_hat = np.concatenate([out[0] for out in output])\n",
    "y_true = np.concatenate([out[1] for out in output])\n",
    "\n",
    "df = pd.DataFrame({'y_true': y_true, 'y_hat': y_hat})\n",
    "df.to_csv(f'{best_model}_pred.csv', index=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(y_true, bins=100, alpha=0.75)\n",
    "ax.hist(y_hat, bins=100, alpha=0.75)\n",
    "ax.legend(['y_true', 'y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "show_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
