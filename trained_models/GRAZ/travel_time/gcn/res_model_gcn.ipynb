{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../src')\n",
    "import os\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from data.datamodule import SHOWDataModule\n",
    "from models.gcn_model import NodeEncodedGCN, NodeEncodedGCN_tt, NodeEncodedGCN_1l, NodeEncodedGCN_2l, NodeEncodedGCN_3l\n",
    "\n",
    "\n",
    "def simple_model_evaluation(y_test, y_pred_test):\n",
    "    # Simple model evaluation that computes and prints MSE, RMSE and MAPE for the training and testing set\n",
    "\n",
    "    # train_error_mse = np.square(y_train - y_pred_train).sum() / y_train.shape[0]\n",
    "    test_error_mse = np.square(y_test - y_pred_test).sum() / y_test.shape[0]\n",
    "\n",
    "    # train_error_mape = (100 / y_train.shape[0]) * (\n",
    "    #    np.absolute(y_train - y_pred_train) / y_train\n",
    "    # ).sum()  # y_train should never be 0 since the travel time in a segment cannot be 0\n",
    "    test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
    "\n",
    "    test_error_mae = (1 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test)).sum()\n",
    "    print(\"-----------MSE----------\")\n",
    "    # print(\"Training error: {}\".format(train_error_mse))\n",
    "    print(\"Testing error: {}\".format(test_error_mse))\n",
    "    print(\"-----------RMSE----------\")\n",
    "    # print(\"Training error: {}\".format(np.sqrt(train_error_mse)))\n",
    "    print(\"Testing error: {}\".format(np.sqrt(test_error_mse)))\n",
    "    print(\"-----------MAPE----------\")\n",
    "    # print(\"Training error: {:.2f} %\".format(train_error_mape))\n",
    "    print(\"Testing error: {:.2f} %\".format(test_error_mape))\n",
    "    print(\"-----------MAE----------\")\n",
    "    print(\"Testing error: {}\".format(test_error_mae))\n",
    "    return test_error_mse, np.sqrt(test_error_mse), test_error_mape, test_error_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the checkpoint directory\n",
    "checkpoint_dir = '.'\n",
    "model_names = os.listdir(checkpoint_dir)\n",
    "\n",
    "# remove all files not ending on ckpt\n",
    "model_names = [model_name for model_name in model_names if model_name.endswith('ckpt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ne_gcn-6730-07271316.ckpt',\n",
       " 'ne_gcn-9070-07271316.ckpt',\n",
       " 'ne_gcn-6278-07271316.ckpt',\n",
       " 'ne_gcn-4231-07271316.ckpt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the datamodule\n",
    "site_name = 'GRAZ'\n",
    "transform = 'maxmin'\n",
    "batch_size = 64\n",
    "empty_graph = False\n",
    "time_kind = 'travel_times'\n",
    "data_module = SHOWDataModule(\n",
    "    site_name=site_name,\n",
    "    transform=transform,\n",
    "    num_lags=2,\n",
    "    train_frac=0.9,\n",
    "    batch_size=batch_size,\n",
    "    empty_graph=empty_graph,\n",
    "    verbose=False,\n",
    "    time_kind=time_kind,\n",
    ")\n",
    "transform = data_module.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-6730-07271316.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/ETA-prediction-autonomous-shuttles/envs/test_env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/manity/SHOW_folder/ETA-prediction-autonomous-shuttles/envs/test_env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/ETA-prediction-autonomous-shuttles/envs/test_env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.92it/s]-----------MSE----------\n",
      "Testing error: 306.3897399902344\n",
      "-----------RMSE----------\n",
      "Testing error: 17.503992080688477\n",
      "-----------MAPE----------\n",
      "Testing error: 10.07 %\n",
      "-----------MAE----------\n",
      "Testing error: 13.412203788757324\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ne_gcn-9070-07271316.ckpt\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 145.11it/s]-----------MSE----------\n",
      "Testing error: 312.5423889160156\n",
      "-----------RMSE----------\n",
      "Testing error: 17.678869247436523\n",
      "-----------MAPE----------\n",
      "Testing error: 10.33 %\n",
      "-----------MAE----------\n",
      "Testing error: 13.684033393859863\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 73.17it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-6278-07271316.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 123.33it/s]-----------MSE----------\n",
      "Testing error: 394.9065246582031\n",
      "-----------RMSE----------\n",
      "Testing error: 19.872255325317383\n",
      "-----------MAPE----------\n",
      "Testing error: 11.20 %\n",
      "-----------MAE----------\n",
      "Testing error: 14.939044952392578\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 60.97it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-4231-07271316.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 104.34it/s]-----------MSE----------\n",
      "Testing error: 362.2132873535156\n",
      "-----------RMSE----------\n",
      "Testing error: 19.031902313232422\n",
      "-----------MAPE----------\n",
      "Testing error: 10.97 %\n",
      "-----------MAE----------\n",
      "Testing error: 14.335135459899902\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 52.84it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the models and evaluate them\n",
    "results = []\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "\n",
    "    # Load model checkpoint\n",
    "    checkpoint_dict = torch.load(model_name)\n",
    "    model = NodeEncodedGCN_1l(\n",
    "        transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "        weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "        lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "        drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "        batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "        input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "        hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "        aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    "    )\n",
    "    model = model.load_from_checkpoint(f'{model_name}')\n",
    "\n",
    "    trainer = pl.Trainer(gpus=1)\n",
    "    results.append(trainer.test(model, datamodule=data_module, verbose=False))\n",
    "\n",
    "# Print the results\n",
    "mse_arr = np.array([run_dict[0]['test/error_mse'] for run_dict in results])\n",
    "mae_arr = np.array([run_dict[0]['test/error_mae'] for run_dict in results])\n",
    "mape_arr = np.array([run_dict[0]['test/error_mape'] for run_dict in results])\n",
    "rmse_arr = np.array([run_dict[0]['test/error_rmse'] for run_dict in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for GRAZ with <class 'data.datamodule.MaxMin'> transform and travel_times time kind\n",
      "MSE: 344.0129852294922 +/- 36.494213129092905\n",
      "MAE: 14.092604398727417 +/- 0.5926968412663832\n",
      "RMSE: 18.5217547416687 +/- 0.9785702787332601\n"
     ]
    }
   ],
   "source": [
    "print(f'Results for {site_name} with {type(transform)} transform and {time_kind} time kind')\n",
    "print(f'MSE: {mse_arr.mean()} +/- {mse_arr.std()}')\n",
    "print(f'MAE: {mae_arr.mean()} +/- {mae_arr.std()}')\n",
    "print(f'RMSE: {rmse_arr.mean()} +/- {rmse_arr.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/ETA-prediction-autonomous-shuttles/envs/test_env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-6730-07271316.ckpt\n",
      "Predicting: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 26.37it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f673a3f2520>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = model_names[np.argmin(mse_arr)]\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint_dict = torch.load(best_model)\n",
    "model = NodeEncodedGCN_1l(\n",
    "    transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "    weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "    lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "    drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "    batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "    input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "    hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "    aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    ")\n",
    "model = model.load_from_checkpoint(f'{best_model}')\n",
    "\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "output = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
    "y_hat = np.concatenate([out[0] for out in output])\n",
    "y_true = np.concatenate([out[1] for out in output])\n",
    "\n",
    "df = pd.DataFrame({'y_true': y_true, 'y_hat': y_hat})\n",
    "df.to_csv(f'{best_model}_pred.csv', index=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(y_true, bins=100, alpha=0.75)\n",
    "ax.hist(y_hat, bins=100, alpha=0.75)\n",
    "ax.legend(['y_true', 'y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "show_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
