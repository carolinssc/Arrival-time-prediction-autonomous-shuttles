{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../../src')\n",
    "import os\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from data.datamodule import SHOWDataModule\n",
    "from models.gcn_model import NodeEncodedGCN, NodeEncodedGCN_tt, NodeEncodedGCN_1l, NodeEncodedGCN_2l, NodeEncodedGCN_3l\n",
    "\n",
    "\n",
    "def simple_model_evaluation(y_test, y_pred_test):\n",
    "    # Simple model evaluation that computes and prints MSE, RMSE and MAPE for the training and testing set\n",
    "\n",
    "    # train_error_mse = np.square(y_train - y_pred_train).sum() / y_train.shape[0]\n",
    "    test_error_mse = np.square(y_test - y_pred_test).sum() / y_test.shape[0]\n",
    "\n",
    "    # train_error_mape = (100 / y_train.shape[0]) * (\n",
    "    #    np.absolute(y_train - y_pred_train) / y_train\n",
    "    # ).sum()  # y_train should never be 0 since the travel time in a segment cannot be 0\n",
    "    test_error_mape = (100 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test) / y_test).sum()\n",
    "\n",
    "    test_error_mae = (1 / y_test.shape[0]) * (np.absolute(y_test - y_pred_test)).sum()\n",
    "    print(\"-----------MSE----------\")\n",
    "    # print(\"Training error: {}\".format(train_error_mse))\n",
    "    print(\"Testing error: {}\".format(test_error_mse))\n",
    "    print(\"-----------RMSE----------\")\n",
    "    # print(\"Training error: {}\".format(np.sqrt(train_error_mse)))\n",
    "    print(\"Testing error: {}\".format(np.sqrt(test_error_mse)))\n",
    "    print(\"-----------MAPE----------\")\n",
    "    # print(\"Training error: {:.2f} %\".format(train_error_mape))\n",
    "    print(\"Testing error: {:.2f} %\".format(test_error_mape))\n",
    "    print(\"-----------MAE----------\")\n",
    "    print(\"Testing error: {}\".format(test_error_mae))\n",
    "    return test_error_mse, np.sqrt(test_error_mse), test_error_mape, test_error_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the checkpoint directory\n",
    "checkpoint_dir = '.'\n",
    "model_names = os.listdir(checkpoint_dir)\n",
    "\n",
    "# remove all files not ending on ckpt\n",
    "model_names = [model_name for model_name in model_names if model_name.endswith('ckpt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ne_gcn-8156-07271310.ckpt',\n",
       " 'ne_gcn-5382-07271310.ckpt',\n",
       " 'ne_gcn-9184-07271310.ckpt',\n",
       " 'ne_gcn-7696-07271310.ckpt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the datamodule\n",
    "site_name = 'GRAZ'\n",
    "transform = 'maxmin'\n",
    "batch_size = 64\n",
    "empty_graph = False\n",
    "time_kind = 'dwell_times'\n",
    "data_module = SHOWDataModule(\n",
    "    site_name=site_name,\n",
    "    transform=transform,\n",
    "    num_lags=2,\n",
    "    train_frac=0.9,\n",
    "    batch_size=batch_size,\n",
    "    empty_graph=empty_graph,\n",
    "    verbose=False,\n",
    "    time_kind=time_kind,\n",
    ")\n",
    "transform = data_module.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [obs.y for obs in data_module.test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-8156-07271310.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  3.04it/s]-----------MSE----------\n",
      "Testing error: 173.76290893554688\n",
      "-----------RMSE----------\n",
      "Testing error: 13.181916236877441\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 8.927206039428711\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  2.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ne_gcn-5382-07271310.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 204.62it/s]-----------MSE----------\n",
      "Testing error: 161.14031982421875\n",
      "-----------RMSE----------\n",
      "Testing error: 12.694106101989746\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 8.75311279296875\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 124.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-9184-07271310.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 153.89it/s]-----------MSE----------\n",
      "Testing error: 166.14569091796875\n",
      "-----------RMSE----------\n",
      "Testing error: 12.889751434326172\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 8.634648323059082\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 91.37it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-7696-07271310.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 130.24it/s]-----------MSE----------\n",
      "Testing error: 166.54055786132812\n",
      "-----------RMSE----------\n",
      "Testing error: 12.905059814453125\n",
      "-----------MAPE----------\n",
      "Testing error: inf %\n",
      "-----------MAE----------\n",
      "Testing error: 8.776200294494629\n",
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 78.30it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the models and evaluate them\n",
    "results = []\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "\n",
    "    # Load model checkpoint\n",
    "    checkpoint_dict = torch.load(model_name)\n",
    "    model = NodeEncodedGCN_1l(\n",
    "        transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "        weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "        lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "        drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "        batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "        input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "        hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "        aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    "    )\n",
    "    model = model.load_from_checkpoint(f'{model_name}')\n",
    "\n",
    "    trainer = pl.Trainer(gpus=1)\n",
    "    results.append(trainer.test(model, datamodule=data_module, verbose=False))\n",
    "\n",
    "# Print the results\n",
    "mse_arr = np.array([run_dict[0]['test/error_mse'] for run_dict in results])\n",
    "mae_arr = np.array([run_dict[0]['test/error_mae'] for run_dict in results])\n",
    "mape_arr = np.array([run_dict[0]['test/error_mape'] for run_dict in results])\n",
    "rmse_arr = np.array([run_dict[0]['test/error_rmse'] for run_dict in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for GRAZ with <class 'data.datamodule.MaxMin'> transform and dwell_times time kind\n",
      "MSE: 166.89736938476562 +/- 4.499210707075144\n",
      "MAE: 8.772791862487793 +/- 0.10407480328123792\n",
      "RMSE: 12.917708396911621 +/- 0.17374215621787598\n"
     ]
    }
   ],
   "source": [
    "print(f'Results for {site_name} with {type(transform)} transform and {time_kind} time kind')\n",
    "print(f'MSE: {mse_arr.mean()} +/- {mse_arr.std()}')\n",
    "print(f'MAE: {mae_arr.mean()} +/- {mae_arr.std()}')\n",
    "print(f'RMSE: {rmse_arr.mean()} +/- {rmse_arr.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/manity/SHOW_folder/SHOW_ML_Service/envs/show_env1/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne_gcn-5382-07271310.ckpt\n",
      "Predicting DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 15.73it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efbd5e0b7c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = model_names[np.argmin(mse_arr)]\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint_dict = torch.load(best_model)\n",
    "model = NodeEncodedGCN_1l(\n",
    "    transform=checkpoint_dict['hyper_parameters']['transform'],\n",
    "    weight_decay=checkpoint_dict['hyper_parameters']['weight_decay'],\n",
    "    lr=checkpoint_dict['hyper_parameters']['lr'],\n",
    "    drop_p=checkpoint_dict['hyper_parameters']['drop_p'],\n",
    "    batch_size=checkpoint_dict['hyper_parameters']['batch_size'],\n",
    "    input_size=checkpoint_dict['hyper_parameters']['input_size'],\n",
    "    hidden_layers=checkpoint_dict['hyper_parameters']['hidden_layers'],\n",
    "    aggregation_function=checkpoint_dict['hyper_parameters']['aggregation_function'],\n",
    ")\n",
    "model = model.load_from_checkpoint(f'{best_model}')\n",
    "\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "output = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
    "y_hat = np.concatenate([out[0] for out in output])\n",
    "y_true = np.concatenate([out[1] for out in output])\n",
    "\n",
    "df = pd.DataFrame({'y_true': y_true, 'y_hat': y_hat})\n",
    "df.to_csv(f'{best_model}_pred.csv', index=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(y_true, bins=100, alpha=0.75)\n",
    "ax.hist(y_hat, bins=100, alpha=0.75)\n",
    "ax.legend(['y_true', 'y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "show_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
